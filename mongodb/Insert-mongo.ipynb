{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from json import dumps\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client[f\"test_mongo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 1 millón de documentos en campos ya indexados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga y el tamaño de almacenamiento de 1 millón de documentos indexados en la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-mongo.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-mongo.py -n 1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El script antes mencionado recibe como entrada la cantidad de documentos que cargará a la base de datos. Secuencialmente, el código creará la nueva colección donde se cargarán los datos, creará los índices correspondientes a todos los campos y cargará la información almacenada en un documento JSON de forma masiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/load_1M_documents_mongo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 1 millón de documentos sobre campos ya indexados ha tomado un tiempo de **1 minuto y 1.51 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en la colección ```extracto_cuenta_1m``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 1000000 documentos en la colección 'extracto_cuenta_1m'\n"
     ]
    }
   ],
   "source": [
    "cnt = db.extracto_cuenta_1m.count_documents({})\n",
    "print(f\"Actualmente existen {cnt} documentos en la colección 'extracto_cuenta_1m'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar el tamaño de los archivos JSON en su forma bruta, antes de cargarse a la base de datos, se utilizará el siguiente script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento random-generated-data-1.json con tamaño en memoria de 259734499 bytes\n"
     ]
    }
   ],
   "source": [
    "file_sizes = []\n",
    "n = 1\n",
    "\n",
    "for i, json_file in enumerate(sorted(os.listdir(\"../json-generated-data\"))):\n",
    "    file_stat = os.stat(os.path.join(\"../json-generated-data\", json_file))\n",
    "    file_sizes.append(file_stat)\n",
    "\n",
    "    if i+1 == n:\n",
    "        break\n",
    "\n",
    "for file in file_sizes:\n",
    "    print(f'Documento {json_file} con tamaño en memoria de {file.st_size} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte de la colección ```extracto_cuenta_1m``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"ns\": \"test_mongo.extracto_cuenta_1m\",\n",
      " \"size\": 206123814,\n",
      " \"count\": 1000000,\n",
      " \"avgObjSize\": 206,\n",
      " \"numOrphanDocs\": 0,\n",
      " \"storageSize\": 103682048,\n",
      " \"freeStorageSize\": 409600,\n",
      " \"capped\": false,\n",
      " \"wiredTiger\": {\n",
      "  \"metadata\": {\n",
      "   \"formatVersion\": 1\n",
      "  },\n",
      "  \"creationString\": \"access_pattern_hint=none\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "r = dumps(db.command(\n",
    "   {\n",
    "     \"collStats\": \"extracto_cuenta_1m\",\n",
    "     \"scale\": 1\n",
    "   }\n",
    "), indent=1)\n",
    "\n",
    "print(r[:300])\n",
    "print(\"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrayendo información importante de los datos recién obtenidos. El tamaño de almacenamiento aproximado de 1 documento de 1 millón de registros con un peso en bruto de 247.70 mb (en escala base binario $2^{20}$), una vez comprimido en la base de datos es **98.87 mb** (en escala base binario $2^{20}$). Esto nos da un radio de compresión de 0.3991 y una reducción de tamaño en memoria del 60.08%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/storage_compass_1M_documents.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la herramienta gráfica compass se puede ver un reporte de 103.27 MB (en escala base decimal $10^{6}$) de tamaño de almacenamiento, lo cual convertido a escala binaria resulta en 98.23 mb, un número aproximado al obtenido mediante el script de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\"indexBuilds\": [],\n",
      " \"totalIndexSize\": 243048448,\n",
      " \"totalSize\": 346730496,\n",
      " \"indexSizes\": {\n",
      "  \"_id_\": 11104256,\n",
      "  \"fecha_1\": 41160704,\n",
      "  \"agencia_1\": 6668288,\n",
      "  \"monto_1\": 34279424,\n",
      "  \"saldo_1\": 36990976,\n",
      "  \"descripcion_1\": 6410240,\n",
      "  \"nota_1\": 106434560\n",
      " },\n",
      " \"scaleFactor\": 1,\n",
      " \"ok\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"...\")\n",
    "print(r[109825:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante que se meustra en compass es el tamaño total de los índices (7 índices en este caso), siendo 243.05 MB (en escala base decimal $10^{6}$) o según los datos extraídos mediante python **231.79 mb** (en escala base binario $2^{20}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una última métrica importante ha revisar es la suma del espacio asignado tanto a los documentos como a los índices en la colección. Es la suma de storageSize y indexSize. En el presente caso resultando un valor de **330.67 mb**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido |\n",
    "|---------------------------------------------|----------------|\n",
    "| Tiempo de carga                             | 1 min 1.52 s   |\n",
    "| Tamaño JSON bruto                           | 247.70 mb      |\n",
    "| Tamaño de almacenamiento en mongoDB         | 98.87 mb       |\n",
    "| Radio de compresión de documento            | 0.3991         |\n",
    "| Reducción de tamaño de memoria de documento | 60.08 %        |\n",
    "| Tamaño total de los índices                 | 231.79 mb      |\n",
    "| Tamaño total de almacenamiento colección    | 330.67 mb      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 10 millones de documentos en campos ya indexados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga y el tamaño de almacenamiento de 10 millones de documentos indexados en la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-mongo.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-mongo.py -n 10\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/load_10M_indexed_documents_mongo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 10 millón de documentos sobre campos ya indexados ha tomado un tiempo de **3 horas 12 minutos y 37.32 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en la colección ```extracto_cuenta_10m``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 10000000 documentos en 'extracto_cuenta_10m'\n"
     ]
    }
   ],
   "source": [
    "cnt = db.extracto_cuenta_10m.count_documents({})\n",
    "print(f\"Actualmente existen {cnt} documentos en 'extracto_cuenta_10m'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar el tamaño de los archivos JSON en su forma bruta, antes de cargarse a la base de datos, se utilizará el siguiente script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento random-generated-data-1.json con tamaño en memoria de 259734499 bytes\n",
      "Documento random-generated-data-10.json con tamaño en memoria de 259687666 bytes\n",
      "Documento random-generated-data-11.json con tamaño en memoria de 259697531 bytes\n",
      "Documento random-generated-data-12.json con tamaño en memoria de 259660386 bytes\n",
      "Documento random-generated-data-13.json con tamaño en memoria de 259651170 bytes\n",
      "Documento random-generated-data-14.json con tamaño en memoria de 259696780 bytes\n",
      "Documento random-generated-data-15.json con tamaño en memoria de 259771941 bytes\n",
      "Documento random-generated-data-16.json con tamaño en memoria de 259765264 bytes\n",
      "Documento random-generated-data-17.json con tamaño en memoria de 259736398 bytes\n",
      "Documento random-generated-data-18.json con tamaño en memoria de 259722533 bytes\n",
      "\n",
      "Sumando un total de 2597124168 bytes\n"
     ]
    }
   ],
   "source": [
    "file_sizes = []\n",
    "file_names = []\n",
    "sum = 0\n",
    "\n",
    "n = 10\n",
    "\n",
    "for i, json_file in enumerate(sorted(os.listdir(\"../json-generated-data\"))):\n",
    "    file_stat = os.stat(os.path.join(\"../json-generated-data\", json_file))\n",
    "    file_sizes.append(file_stat)\n",
    "    file_names.append(json_file)\n",
    "    sum = sum + int(file_stat.st_size)\n",
    "    \n",
    "    if i+1 == n:\n",
    "        break\n",
    "\n",
    "for file, f_name in zip(file_sizes, file_names):\n",
    "    print(f'Documento {f_name} con tamaño en memoria de {file.st_size} bytes')\n",
    "\n",
    "print(\"\")\n",
    "print(f'Sumando un total de {sum} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte de la colección ```extracto_cuenta_10m``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"ns\": \"test_mongo.extracto_cuenta_10m\",\n",
      " \"size\": 2061015647,\n",
      " \"count\": 10000000,\n",
      " \"avgObjSize\": 206,\n",
      " \"numOrphanDocs\": 0,\n",
      " \"storageSize\": 1043173376,\n",
      " \"freeStorageSize\": 2236416,\n",
      " \"capped\": false,\n",
      " \"wiredTiger\": {\n",
      "  \"metadata\": {\n",
      "   \"formatVersion\": 1\n",
      "  },\n",
      "  \"creationString\": \"access_pattern_hint\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "r = dumps(db.command(\n",
    "   {\n",
    "     \"collStats\": \"extracto_cuenta_10m\",\n",
    "     \"scale\": 1\n",
    "   }\n",
    "), indent=1)\n",
    "\n",
    "print(r[:300])\n",
    "print(\"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrayendo información importante de los datos recién obtenidos. El tamaño de almacenamiento de 10 documentos de 1 millón de registros con un peso en total en bruto de 2.41 gb (en escala base binario $2^{20}$), una vez comprimido en la base de datos es **0.97 gb** (en escala base binario $2^{20}$). Esto nos da un radio de compresión de 0.4017 y una reducción de tamaño en memoria del 59.83%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 10 millones de documentos](../imagenes-de-soporte/mongo-insert/storage_compass_10M_documents.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la herramienta gráfica compass se puede ver un reporte de 1.04 GB (en escala base decimal $10^{6}$) de tamaño de almacenamiento, lo cual convertido a escala binaria resulta en 0.968 gb, un número aproximado al obtenido mediante el script de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      " },\n",
      " \"indexBuilds\": [],\n",
      " \"totalIndexSize\": 3362054144,\n",
      " \"totalSize\": 4405227520,\n",
      " \"indexSizes\": {\n",
      "  \"_id_\": 118546432,\n",
      "  \"fecha_1\": 601604096,\n",
      "  \"agencia_1\": 59777024,\n",
      "  \"monto_1\": 514748416,\n",
      "  \"saldo_1\": 563314688,\n",
      "  \"descripcion_1\": 57679872,\n",
      "  \"nota_1\": 1446383616\n",
      " },\n",
      " \"scaleFactor\": 1,\n",
      " \"ok\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"...\")\n",
    "print(r[109772:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante que se meustra en compass es el tamaño total de los índices (7 índices en este caso), siendo 3.36 GB (en escala base decimal $10^{6}$) o según los datos extraídos mediante python **3.13 gb** (en escala base binario $2^{20}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una última métrica importante ha revisar es la suma del espacio asignado tanto a los documentos como a los índices en la colección. Es la suma de storageSize y indexSize. En el presente caso resultando un valor de **4.10 gb**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido       |\n",
    "|---------------------------------------------|----------------------|\n",
    "| Tiempo de carga                             | 3 h 12 min y 37.32 s |\n",
    "| Tamaño JSON bruto                           | 2.41 gb              |\n",
    "| Tamaño de almacenamiento en mongoDB         | 0.97 gb              |\n",
    "| Radio de compresión de documento            | 0.4017               |\n",
    "| Reducción de tamaño de memoria de documento | 59.83 %              |\n",
    "| Tamaño total de los índices                 | 3.13 gb              |\n",
    "| Tamaño total de almacenamiento colección    | 4.10 gb              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 1 millón de documentos y posterior indexación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga de 1 millón de documentos en una colección sin índices y el tamaño de almacenamiento de dicha cantidad de documentos una vez ya indexados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-mongo-no-index.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-mongo-no-index.py -n 1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El script antes mencionado recibe como entrada la cantidad de documentos que cargará a la base de datos. Secuencialmente, el código creará la nueva colección donde se cargarán los datos, cargará la información almacenada en un documento JSON de forma masiva, y creará finalmente los índices correspondientes a todos los campos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/load_1M_documentos_no_index_mongo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 1 millón de documentos sobre campos y posteriormente indexar todos los campos ha tomado un tiempo de **35.36 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en la colección ```extracto_cuenta_1m2``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 1000000 documentos en la colección 'extracto_cuenta_1m2'\n"
     ]
    }
   ],
   "source": [
    "cnt = db.extracto_cuenta_1m2.count_documents({})\n",
    "print(f\"Actualmente existen {cnt} documentos en la colección 'extracto_cuenta_1m2'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte de la colección ```extracto_cuenta_1m2``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"ns\": \"test_mongo.extracto_cuenta_1m2\",\n",
      " \"size\": 206123814,\n",
      " \"count\": 1000000,\n",
      " \"avgObjSize\": 206,\n",
      " \"numOrphanDocs\": 0,\n",
      " \"storageSize\": 100823040,\n",
      " \"freeStorageSize\": 0,\n",
      " \"capped\": false,\n",
      " \"wiredTiger\": {\n",
      "  \"metadata\": {\n",
      "   \"formatVersion\": 1\n",
      "  },\n",
      "  \"creationString\": \"access_pattern_hint=none,all\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "r = dumps(db.command(\n",
    "   {\n",
    "     \"collStats\": \"extracto_cuenta_1m2\",\n",
    "     \"scale\": 1\n",
    "   }\n",
    "), indent=1)\n",
    "\n",
    "print(r[:300])\n",
    "print(\"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por los datos recopilados anteriormente se sabe que 1 documento de 1 millón de registros con un peso en bruto de 247.70 mb (en escala base binario $2^{20}$), una vez comprimido en la base de datos, para esta prueba en particular es **96.15 mb** (en escala base binario $2^{20}$). Esto nos da un radio de compresión de 0.3882 y una reducción de tamaño en memoria del 61.18%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/storage_compass_1M_documentos_no_index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la herramienta gráfica compass se puede ver un reporte de 100.82 MB (en escala base decimal $10^{6}$) de tamaño de almacenamiento, lo cual convertido a escala binaria resulta en 96.15 mb, un número aproximado al obtenido mediante el script de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      " },\n",
      " \"indexBuilds\": [],\n",
      " \"totalIndexSize\": 128323584,\n",
      " \"totalSize\": 229146624,\n",
      " \"indexSizes\": {\n",
      "  \"_id_\": 10743808,\n",
      "  \"fecha_1\": 20262912,\n",
      "  \"agencia_1\": 5373952,\n",
      "  \"monto_1\": 16683008,\n",
      "  \"saldo_1\": 18006016,\n",
      "  \"descripcion_1\": 5603328,\n",
      "  \"nota_1\": 51650560\n",
      " },\n",
      " \"scaleFactor\": 1,\n",
      " \"ok\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"...\")\n",
    "print(r[109788:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante que se meustra en compass es el tamaño total de los índices (7 índices en este caso), siendo 128.32 MB (en escala base decimal $10^{6}$) o según los datos extraídos mediante python **122.37 mb** (en escala base binario $2^{20}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una última métrica importante ha revisar es la suma del espacio asignado tanto a los documentos como a los índices en la colección. Es la suma de storageSize y indexSize. En el presente caso resultando un valor de **218.53 mb**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido |\n",
    "|---------------------------------------------|----------------|\n",
    "| Tiempo de carga                             | 35.36 s        |\n",
    "| Tamaño JSON bruto                           | 247.70 mb      |\n",
    "| Tamaño de almacenamiento en mongoDB         | 96.15 mb       |\n",
    "| Radio de compresión de documento            | 0.3882         |\n",
    "| Reducción de tamaño de memoria de documento | 61.18 %        |\n",
    "| Tamaño total de los índices                 | 122.37 mb      |\n",
    "| Tamaño total de almacenamiento colección    | 218.53 mb      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 10 millones de documentos y posterior indexación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga de 10 millones de documentos en una colección sin índices y el tamaño de almacenamiento de dicha cantidad de documentos una vez ya indexados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-mongo-no-index.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-mongo-no-index.py -n 10\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El script antes mencionado recibe como entrada la cantidad de documentos que cargará a la base de datos. Secuencialmente, el código creará la nueva colección donde se cargarán los datos, cargará la información almacenada en un documento JSON de forma masiva, y creará finalmente los índices correspondientes a todos los campos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/load_10M_documentos_no_index_mongo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 1 millón de documentos sobre campos y posteriormente indexar todos los campos ha tomado un tiempo de **7 minutos 1.82 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en la colección ```extracto_cuenta_10m2``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 1000000 documentos en la colección 'extracto_cuenta_10m2'\n"
     ]
    }
   ],
   "source": [
    "cnt = db.extracto_cuenta_10m2.count_documents({})\n",
    "print(f\"Actualmente existen {cnt} documentos en la colección 'extracto_cuenta_10m2'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte de la colección ```extracto_cuenta_10m2``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"ns\": \"test_mongo.extracto_cuenta_10m2\",\n",
      " \"size\": 2061015647,\n",
      " \"count\": 10000000,\n",
      " \"avgObjSize\": 206,\n",
      " \"numOrphanDocs\": 0,\n",
      " \"storageSize\": 1004490752,\n",
      " \"freeStorageSize\": 2162688,\n",
      " \"capped\": false,\n",
      " \"wiredTiger\": {\n",
      "  \"metadata\": {\n",
      "   \"formatVersion\": 1\n",
      "  },\n",
      "  \"creationString\": \"access_pattern_hin\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "r = dumps(db.command(\n",
    "   {\n",
    "     \"collStats\": \"extracto_cuenta_10m2\",\n",
    "     \"scale\": 1\n",
    "   }\n",
    "), indent=1)\n",
    "\n",
    "print(r[:300])\n",
    "print(\"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tamaño de almacenamiento de 10 documentos de 1 millón de registros con un peso en total en bruto de 2.41 gb (en escala base binario $2^{20}$), una vez comprimido en la base de datos es **0.93 gb** (en escala base binario $2^{20}$). Esto nos da un radio de compresión de 0.3868 y una reducción de tamaño en memoria del 61.32%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/storage_compass_10M_documentos_no_index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la herramienta gráfica compass se puede ver un reporte de 1.00 GB (en escala base decimal $10^{6}$) de tamaño de almacenamiento, lo cual convertido a escala binaria resulta en 93.13 mb, un número aproximado al obtenido mediante el script de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      " },\n",
      " \"indexBuilds\": [],\n",
      " \"totalIndexSize\": 1226719232,\n",
      " \"totalSize\": 2231209984,\n",
      " \"indexSizes\": {\n",
      "  \"_id_\": 110129152,\n",
      "  \"fecha_1\": 186114048,\n",
      "  \"agencia_1\": 53514240,\n",
      "  \"monto_1\": 158367744,\n",
      "  \"saldo_1\": 173264896,\n",
      "  \"descripcion_1\": 55648256,\n",
      "  \"nota_1\": 489680896\n",
      " },\n",
      " \"scaleFactor\": 1,\n",
      " \"ok\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"...\")\n",
    "print(r[109935:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante que se meustra en compass es el tamaño total de los índices (7 índices en este caso), siendo 1.23 GB (en escala base decimal $10^{6}$) o según los datos extraídos mediante python **1.14 gb** (en escala base binario $2^{20}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una última métrica importante ha revisar es la suma del espacio asignado tanto a los documentos como a los índices en la colección. Es la suma de storageSize y indexSize. En el presente caso resultando un valor de **2.08 gb**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido |\n",
    "|---------------------------------------------|----------------|\n",
    "| Tiempo de carga                             | 7 min 1.82 s   |\n",
    "| Tamaño JSON bruto                           | 2.41 gb        |\n",
    "| Tamaño de almacenamiento en mongoDB         | 0.93 gb        |\n",
    "| Radio de compresión de documento            | 0.3868         |\n",
    "| Reducción de tamaño de memoria de documento | 61.32 %        |\n",
    "| Tamaño total de los índices                 | 1.14 gb        |\n",
    "| Tamaño total de almacenamiento colección    | 2.08 gb        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 30 millones de documentos y posterior indexación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga de 30 millones de documentos en una colección sin índices y el tamaño de almacenamiento de dicha cantidad de documentos una vez ya indexados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-mongo-no-index.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-mongo-no-index.py -n 30\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El script antes mencionado recibe como entrada la cantidad de documentos que cargará a la base de datos. Secuencialmente, el código creará la nueva colección donde se cargarán los datos, cargará la información almacenada en un documento JSON de forma masiva, y creará finalmente los índices correspondientes a todos los campos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/load_30M_documentos_mongo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 30 millones de documentos sobre campos y posteriormente indexar todos los campos ha tomado un tiempo de **37 minutos 31.62 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en la colección ```extracto_cuenta_30m``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 30000000 documentos en 'extracto_cuenta_30m'\n"
     ]
    }
   ],
   "source": [
    "cnt = db.extracto_cuenta_30m.count_documents({})\n",
    "print(f\"Actualmente existen {cnt} documentos en 'extracto_cuenta_30m'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar el tamaño de los archivos JSON en su forma bruta, antes de cargarse a la base de datos, se utilizará el siguiente script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento random-generated-data-1.json con tamaño en memoria de 259734499 bytes\n",
      "Documento random-generated-data-10.json con tamaño en memoria de 259687666 bytes\n",
      "Documento random-generated-data-11.json con tamaño en memoria de 259697531 bytes\n",
      "Documento random-generated-data-12.json con tamaño en memoria de 259660386 bytes\n",
      "Documento random-generated-data-13.json con tamaño en memoria de 259651170 bytes\n",
      "Documento random-generated-data-14.json con tamaño en memoria de 259696780 bytes\n",
      "Documento random-generated-data-15.json con tamaño en memoria de 259771941 bytes\n",
      "Documento random-generated-data-16.json con tamaño en memoria de 259765264 bytes\n",
      "Documento random-generated-data-17.json con tamaño en memoria de 259736398 bytes\n",
      "Documento random-generated-data-18.json con tamaño en memoria de 259722533 bytes\n",
      "Documento random-generated-data-19.json con tamaño en memoria de 259695669 bytes\n",
      "Documento random-generated-data-2.json con tamaño en memoria de 259739233 bytes\n",
      "Documento random-generated-data-20.json con tamaño en memoria de 259719008 bytes\n",
      "Documento random-generated-data-21.json con tamaño en memoria de 259769492 bytes\n",
      "Documento random-generated-data-22.json con tamaño en memoria de 259702477 bytes\n",
      "Documento random-generated-data-23.json con tamaño en memoria de 259717193 bytes\n",
      "Documento random-generated-data-24.json con tamaño en memoria de 259680473 bytes\n",
      "Documento random-generated-data-25.json con tamaño en memoria de 259720743 bytes\n",
      "Documento random-generated-data-26.json con tamaño en memoria de 259702629 bytes\n",
      "Documento random-generated-data-27.json con tamaño en memoria de 259688801 bytes\n",
      "Documento random-generated-data-28.json con tamaño en memoria de 259680429 bytes\n",
      "Documento random-generated-data-29.json con tamaño en memoria de 259690215 bytes\n",
      "Documento random-generated-data-3.json con tamaño en memoria de 259672974 bytes\n",
      "Documento random-generated-data-30.json con tamaño en memoria de 259711947 bytes\n",
      "Documento random-generated-data-4.json con tamaño en memoria de 259706379 bytes\n",
      "Documento random-generated-data-5.json con tamaño en memoria de 259739617 bytes\n",
      "Documento random-generated-data-6.json con tamaño en memoria de 259653811 bytes\n",
      "Documento random-generated-data-7.json con tamaño en memoria de 259684247 bytes\n",
      "Documento random-generated-data-8.json con tamaño en memoria de 259721647 bytes\n",
      "Documento random-generated-data-9.json con tamaño en memoria de 259717709 bytes\n",
      "\n",
      "Sumando un total de 7791238861 bytes\n"
     ]
    }
   ],
   "source": [
    "file_sizes = []\n",
    "file_names = []\n",
    "sum = 0\n",
    "\n",
    "n = 30\n",
    "\n",
    "for i, json_file in enumerate(sorted(os.listdir(\"../json-generated-data\"))):\n",
    "    file_stat = os.stat(os.path.join(\"../json-generated-data\", json_file))\n",
    "    file_sizes.append(file_stat)\n",
    "    file_names.append(json_file)\n",
    "    sum = sum + int(file_stat.st_size)\n",
    "    \n",
    "    if i+1 == n:\n",
    "        break\n",
    "\n",
    "for file, f_name in zip(file_sizes, file_names):\n",
    "    print(f'Documento {f_name} con tamaño en memoria de {file.st_size} bytes')\n",
    "\n",
    "print(\"\")\n",
    "print(f'Sumando un total de {sum} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte de la colección ```extracto_cuenta_30m2``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"ns\": \"test_mongo.extracto_cuenta_30m\",\n",
      " \"size\": 6182911222,\n",
      " \"count\": 30000000,\n",
      " \"avgObjSize\": 206,\n",
      " \"numOrphanDocs\": 0,\n",
      " \"storageSize\": 2984677376,\n",
      " \"freeStorageSize\": 954368,\n",
      " \"capped\": false,\n",
      " \"wiredTiger\": {\n",
      "  \"metadata\": {\n",
      "   \"formatVersion\": 1\n",
      "  },\n",
      "  \"creationString\": \"access_pattern_hint=\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "r = dumps(db.command(\n",
    "   {\n",
    "     \"collStats\": \"extracto_cuenta_30m\",\n",
    "     \"scale\": 1\n",
    "   }\n",
    "), indent=1)\n",
    "\n",
    "print(r[:300])\n",
    "print(\"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tamaño de almacenamiento de 30 documentos de 1 millón de registros con un peso en total en bruto de 7.26 gb (en escala base binario $2^{20}$), una vez comprimido en la base de datos es **2.78 gb** (en escala base binario $2^{20}$). Esto nos da un radio de compresión de 0.3830 y una reducción de tamaño en memoria del 61.69%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/storage_compass_30M_documentos_no_index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la herramienta gráfica compass se puede ver un reporte de 2.98 GB (en escala base decimal $10^{6}$) de tamaño de almacenamiento, lo cual convertido a escala binaria resulta en 2.78 gb, un número aproximado al obtenido mediante el script de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\n",
      " },\n",
      " \"indexBuilds\": [],\n",
      " \"totalIndexSize\": 3570143232,\n",
      " \"totalSize\": 6554820608,\n",
      " \"indexSizes\": {\n",
      "  \"_id_\": 331038720,\n",
      "  \"fecha_1\": 512319488,\n",
      "  \"agencia_1\": 160526336,\n",
      "  \"monto_1\": 468492288,\n",
      "  \"saldo_1\": 493805568,\n",
      "  \"descripcion_1\": 166879232,\n",
      "  \"nota_1\": 1437081600\n",
      " },\n",
      " \"scaleFactor\": 1,\n",
      " \"ok\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"...\")\n",
    "print(r[109750:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante que se meustra en compass es el tamaño total de los índices (7 índices en este caso), siendo 3.32 GB (en escala base decimal $10^{9}$) o según los datos extraídos mediante python **3.32 gb** (en escala base binario $2^{20}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una última métrica importante ha revisar es la suma del espacio asignado tanto a los documentos como a los índices en la colección. Es la suma de storageSize y indexSize. En el presente caso resultando un valor de **6.10 gb**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido |\n",
    "|---------------------------------------------|----------------|\n",
    "| Tiempo de carga                             | 37 min 31.62 s |\n",
    "| Tamaño JSON bruto                           | 7.26 gb        |\n",
    "| Tamaño de almacenamiento en mongoDB         | 2.68 gb        |\n",
    "| Radio de compresión de documento            | 0.3830         |\n",
    "| Reducción de tamaño de memoria de documento | 61.69 %        |\n",
    "| Tamaño total de los índices                 | 3.32 gb        |\n",
    "| Tamaño total de almacenamiento colección    | 6.10 gb        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7e5a1f785ed82844e2da5d30522181462e1597dbd1807cbc4c5c0cc1d5a2e0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
