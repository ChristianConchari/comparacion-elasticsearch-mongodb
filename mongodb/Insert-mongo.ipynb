{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from json import dumps\n",
    "from numpy import asarray, mean\n",
    "import os\n",
    "from random import randrange, choice, uniform\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "from random import randint\n",
    "from lorem_text import lorem\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client[f\"test_mongo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de documentos individualmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará el tiempo de carga de 10 000 documentos que serán generados aleatoriamente y posteriormente serán cargados de manera individual secuencialmente a la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de datos aleatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La celda a continuación muestra el script usado para generar los datos aleatorios. Un código similar será incluido en el script será utilizado para generar los documentos JSON que se utilizarán en las siguientes secciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_date(start, end):\n",
    "    delta = end - start\n",
    "    int_delta = (delta.days * 24 * 60 * 60) + delta.seconds\n",
    "    random_second = randrange(int_delta)\n",
    "    return start + timedelta(seconds=random_second)\n",
    "\n",
    "d1 = datetime.strptime('1/1/1950 12:59 PM', '%m/%d/%Y %I:%M %p')\n",
    "d2 = datetime.strptime('1/1/2022 01:00 AM', '%m/%d/%Y %I:%M %p')\n",
    "\n",
    "descripciones = [\n",
    "    'Transferencia interbancaria SIMPLE',\n",
    "    'DEB.CTA.P/C.INTERNET',\n",
    "    'Debito Cta por ACH',\n",
    "    'Retiro en efectivo',\n",
    "    'AB.CTA.P/MOVIL',\n",
    "    'Pago recibo de agua',\n",
    "    'Debito Cta por compra',\n",
    "    'Debito Cta por pago de Seguro',\n",
    "    'Retención IVA',\n",
    "    'Cargo por cobro de servicio',\n",
    "    'Cobro seguro',\n",
    "    'Intereses',\n",
    "    'Ingreso en efectivo',\n",
    "    'Reintegro cajero automático',\n",
    "    'Pago de cheque compensado',\n",
    "    'Pago recibo de luz',\n",
    "    'Deposito a cuenta',\n",
    "    'Comisión de mantenimiento',\n",
    "    'Pago en interés',\n",
    "    'Consignación en efectivo',\n",
    "    'Pago recibo de gas',\n",
    "    'Compra en comercio',\n",
    "    'Apertura de cuenta corriente',\n",
    "    'Pago de nómina',\n",
    "    'Capitalización de intereses premio',\n",
    "    'Aporte inversor',\n",
    "    'Pago de servicio telefónico',\n",
    "    'Transferencia de fondos de ahorros',\n",
    "    'Pago en línea - Servicio de internet',\n",
    "    'Apertura de caja de ahorros'\n",
    "]\n",
    "\n",
    "agencias = ['La Paz',\n",
    "            'Oruro', \n",
    "            'Cochabamba', \n",
    "            'Chuquisaca', \n",
    "            'Pando', \n",
    "            'Beni', \n",
    "            'Santa Cruz', \n",
    "            'Tarija'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de índices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La celda a continuación muestra el script usado para crear los índices de los campos. Un código similar será incluido en el script será utilizado para cargar los documentos a la base de datos en las siguientes secciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id_': {'v': 2, 'key': [('_id', 1)]},\n",
       " 'fecha_1': {'v': 2, 'key': [('fecha', 1)]},\n",
       " 'agencia_1': {'v': 2, 'key': [('agencia', 1)]},\n",
       " 'monto_1': {'v': 2, 'key': [('monto', 1)]},\n",
       " 'saldo_1': {'v': 2, 'key': [('saldo', 1)]},\n",
       " 'descripcion_1': {'v': 2, 'key': [('descripcion', 1)]},\n",
       " 'nota_1': {'v': 2, 'key': [('nota', 1)]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.create_collection(f\"extracto_cuenta_seq\")\n",
    "\n",
    "db.extracto_cuenta_seq.create_index('fecha')\n",
    "db.extracto_cuenta_seq.create_index('agencia')\n",
    "db.extracto_cuenta_seq.create_index('monto')\n",
    "db.extracto_cuenta_seq.create_index('saldo')\n",
    "db.extracto_cuenta_seq.create_index('descripcion')\n",
    "db.extracto_cuenta_seq.create_index('nota')\n",
    "\n",
    "db.extracto_cuenta_seq.index_information()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de 10 000 registros de forma individual secuencialmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el script a continuación se cargarán 10 000 registros generados aleatoriamente de manera individual y secuencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo promedio de carga de un solo documento: 0:00:00.000865\n",
      "Tiempo de carga de datos: 0:00:09.350930\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "time_insert_one = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    fecha = random_date(d1, d2)\n",
    "    agencia = choice(agencias)\n",
    "    monto = round(uniform(10.0, 400000.0), 2)\n",
    "    descripcion = choice(descripciones)\n",
    "    saldo = round(uniform(0.0, 10000000.0), 2)\n",
    "    nota = lorem.words(randint(1,13))\n",
    "\n",
    "    insert_data = {\n",
    "        'fecha': fecha,\n",
    "        'agencia': agencia,\n",
    "        'monto': monto,\n",
    "        'descripcion': descripcion,\n",
    "        'saldo': saldo,\n",
    "        'nota': nota\n",
    "    }\n",
    "\n",
    "    one_start_time = time.time()\n",
    "    db.extracto_cuenta_seq.insert_one(insert_data)\n",
    "    one_end_time = time.time()\n",
    "\n",
    "    time_insert_one.append(one_end_time-one_start_time)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "avg_insert_one_time = mean(asarray(time_insert_one))\n",
    "\n",
    "# Mostramos los resultados en consola\n",
    "\n",
    "print(f'Tiempo promedio de carga de un solo documento: {str(timedelta(seconds = avg_insert_one_time))}')\n",
    "print(f'Tiempo de carga de datos: {str(timedelta(seconds = (end_time - start_time)))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según muestran los resultados de ejecución de la celda superior, se tiene un tiempo promedio de carga por documento de **0.86 milisegundos**, y un tiempo total de carga del total de 10 000 documentos de **9.35 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en el índice ```extracto_cuenta_seq``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 10 documentos en el índice 'extracto_cuenta_seq'\n"
     ]
    }
   ],
   "source": [
    "cnt = es.cat.count(index=\"extracto_cuenta_seq\", format= \"json\")[0]['count']\n",
    "print(f\"Actualmente existen {cnt} documentos en el índice 'extracto_cuenta_seq'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 1 millón de documentos en campos ya indexados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga y el tamaño de almacenamiento de 1 millón de documentos indexados en la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-mongo.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-mongo.py -n 1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/load_1M_documents_mongo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 1 millón de documentos sobre campos ya indexados ha tomado un tiempo de **1 minuto y 1.51 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en la colección ```extracto_cuenta_1m``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 1000000 documentos en la colección 'extracto_cuenta_1m'\n"
     ]
    }
   ],
   "source": [
    "cnt = db.extracto_cuenta_1m.count_documents({})\n",
    "print(f\"Actualmente existen {cnt} documentos en la colección 'extracto_cuenta_1m'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar el tamaño de los archivos JSON en su forma bruta, antes de cargarse a la base de datos, se utilizará el siguiente script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento random-generated-data-1.json con tamaño en memoria de 259734499 bytes\n"
     ]
    }
   ],
   "source": [
    "file_sizes = []\n",
    "n = 1\n",
    "\n",
    "for i, json_file in enumerate(sorted(os.listdir(\"../json-generated-data\"))):\n",
    "    file_stat = os.stat(os.path.join(\"../json-generated-data\", json_file))\n",
    "    file_sizes.append(file_stat)\n",
    "\n",
    "    if i+1 == n:\n",
    "        break\n",
    "\n",
    "for file in file_sizes:\n",
    "    print(f'Documento {json_file} con tamaño en memoria de {file.st_size} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte de la colección ```extracto_cuenta_1m``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"ns\": \"test_mongo.extracto_cuenta_1m\",\n",
      " \"size\": 206123814,\n",
      " \"count\": 1000000,\n",
      " \"avgObjSize\": 206,\n",
      " \"numOrphanDocs\": 0,\n",
      " \"storageSize\": 103682048,\n",
      " \"freeStorageSize\": 409600,\n",
      " \"capped\": false,\n",
      " \"wiredTiger\": {\n",
      "  \"metadata\": {\n",
      "   \"formatVersion\": 1\n",
      "  },\n",
      "  \"creationString\": \"access_pattern_hint=none\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "r = dumps(db.command(\n",
    "   {\n",
    "     \"collStats\": \"extracto_cuenta_1m\",\n",
    "     \"scale\": 1\n",
    "   }\n",
    "), indent=1)\n",
    "\n",
    "print(r[:300])\n",
    "print(\"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrayendo información importante de los datos recién obtenidos. El tamaño de almacenamiento aproximado de 1 documento de 1 millón de registros con un peso en bruto de 247.70 mb (en escala base binario $2^{20}$), una vez comprimido en la base de datos es **98.87 mb** (en escala base binario $2^{20}$). Esto nos da un radio de compresión de 0.3991 y una reducción de tamaño en memoria del 60.08%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/storage_compass_1M_documents.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la herramienta gráfica compass se puede ver un reporte de 103.27 MB (en escala base decimal $10^{6}$) de tamaño de almacenamiento, lo cual convertido a escala binaria resulta en 98.23 mb, un número aproximado al obtenido mediante el script de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\"indexBuilds\": [],\n",
      " \"totalIndexSize\": 243048448,\n",
      " \"totalSize\": 346730496,\n",
      " \"indexSizes\": {\n",
      "  \"_id_\": 11104256,\n",
      "  \"fecha_1\": 41160704,\n",
      "  \"agencia_1\": 6668288,\n",
      "  \"monto_1\": 34279424,\n",
      "  \"saldo_1\": 36990976,\n",
      "  \"descripcion_1\": 6410240,\n",
      "  \"nota_1\": 106434560\n",
      " },\n",
      " \"scaleFactor\": 1,\n",
      " \"ok\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"...\")\n",
    "print(r[109825:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante que se meustra en compass es el tamaño total de los índices (7 índices en este caso), siendo 243.05 MB (en escala base decimal $10^{6}$) o según los datos extraídos mediante python **231.79 mb** (en escala base binario $2^{20}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una última métrica importante ha revisar es la suma del espacio asignado tanto a los documentos como a los índices en la colección. Es la suma de storageSize y indexSize. En el presente caso resultando un valor de **330.67 mb**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido |\n",
    "|---------------------------------------------|----------------|\n",
    "| Tiempo de carga                             | 1 min 1.52 s   |\n",
    "| Tamaño JSON bruto                           | 247.70 mb      |\n",
    "| Tamaño de almacenamiento en mongoDB         | 98.87 mb       |\n",
    "| Radio de compresión de documento            | 0.3991         |\n",
    "| Reducción de tamaño de memoria de documento | 60.08 %        |\n",
    "| Tamaño total de los índices                 | 231.79 mb      |\n",
    "| Tamaño total de almacenamiento colección    | 330.67 mb      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 10 millones de documentos en campos ya indexados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga y el tamaño de almacenamiento de 10 millones de documentos indexados en la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-mongo.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-mongo.py -n 10\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/load_10M_indexed_documents_mongo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 10 millón de documentos sobre campos ya indexados ha tomado un tiempo de **3 horas 12 minutos y 37.32 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en la colección ```extracto_cuenta_10m``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 10000000 documentos en 'extracto_cuenta_10m'\n"
     ]
    }
   ],
   "source": [
    "cnt = db.extracto_cuenta_10m.count_documents({})\n",
    "print(f\"Actualmente existen {cnt} documentos en 'extracto_cuenta_10m'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar el tamaño de los archivos JSON en su forma bruta, antes de cargarse a la base de datos, se utilizará el siguiente script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento random-generated-data-1.json con tamaño en memoria de 259734499 bytes\n",
      "Documento random-generated-data-10.json con tamaño en memoria de 259687666 bytes\n",
      "Documento random-generated-data-11.json con tamaño en memoria de 259697531 bytes\n",
      "Documento random-generated-data-12.json con tamaño en memoria de 259660386 bytes\n",
      "Documento random-generated-data-13.json con tamaño en memoria de 259651170 bytes\n",
      "Documento random-generated-data-14.json con tamaño en memoria de 259696780 bytes\n",
      "Documento random-generated-data-15.json con tamaño en memoria de 259771941 bytes\n",
      "Documento random-generated-data-16.json con tamaño en memoria de 259765264 bytes\n",
      "Documento random-generated-data-17.json con tamaño en memoria de 259736398 bytes\n",
      "Documento random-generated-data-18.json con tamaño en memoria de 259722533 bytes\n",
      "\n",
      "Sumando un total de 2597124168 bytes\n"
     ]
    }
   ],
   "source": [
    "file_sizes = []\n",
    "file_names = []\n",
    "sum = 0\n",
    "\n",
    "n = 10\n",
    "\n",
    "for i, json_file in enumerate(sorted(os.listdir(\"../json-generated-data\"))):\n",
    "    file_stat = os.stat(os.path.join(\"../json-generated-data\", json_file))\n",
    "    file_sizes.append(file_stat)\n",
    "    file_names.append(json_file)\n",
    "    sum += int(file_stat.st_size)\n",
    "    \n",
    "    if i+1 == n:\n",
    "        break\n",
    "\n",
    "for file, f_name in zip(file_sizes, file_names):\n",
    "    print(f'Documento {f_name} con tamaño en memoria de {file.st_size} bytes')\n",
    "\n",
    "print(\"\")\n",
    "print(f'Sumando un total de {sum} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte de la colección ```extracto_cuenta_10m``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"ns\": \"test_mongo.extracto_cuenta_10m\",\n",
      " \"size\": 2061015647,\n",
      " \"count\": 10000000,\n",
      " \"avgObjSize\": 206,\n",
      " \"numOrphanDocs\": 0,\n",
      " \"storageSize\": 1043173376,\n",
      " \"freeStorageSize\": 2236416,\n",
      " \"capped\": false,\n",
      " \"wiredTiger\": {\n",
      "  \"metadata\": {\n",
      "   \"formatVersion\": 1\n",
      "  },\n",
      "  \"creationString\": \"access_pattern_hint\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "r = dumps(db.command(\n",
    "   {\n",
    "     \"collStats\": \"extracto_cuenta_10m\",\n",
    "     \"scale\": 1\n",
    "   }\n",
    "), indent=1)\n",
    "\n",
    "print(r[:300])\n",
    "print(\"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrayendo información importante de los datos recién obtenidos. El tamaño de almacenamiento de 10 documentos de 1 millón de registros con un peso en total en bruto de 2.41 gb (en escala base binario $2^{30}$), una vez comprimido en la base de datos es **0.97 gb** (en escala base binario $2^{30}$). Esto nos da un radio de compresión de 0.4017 y una reducción de tamaño en memoria del 59.83%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 10 millones de documentos](../imagenes-de-soporte/mongo-insert/storage_compass_10M_documents.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la herramienta gráfica compass se puede ver un reporte de 1.04 GB (en escala base decimal) de tamaño de almacenamiento, lo cual convertido a escala binaria resulta en 0.968 gb, un número aproximado al obtenido mediante el script de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      " },\n",
      " \"indexBuilds\": [],\n",
      " \"totalIndexSize\": 3362054144,\n",
      " \"totalSize\": 4405227520,\n",
      " \"indexSizes\": {\n",
      "  \"_id_\": 118546432,\n",
      "  \"fecha_1\": 601604096,\n",
      "  \"agencia_1\": 59777024,\n",
      "  \"monto_1\": 514748416,\n",
      "  \"saldo_1\": 563314688,\n",
      "  \"descripcion_1\": 57679872,\n",
      "  \"nota_1\": 1446383616\n",
      " },\n",
      " \"scaleFactor\": 1,\n",
      " \"ok\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"...\")\n",
    "print(r[109772:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante que se meustra en compass es el tamaño total de los índices (7 índices en este caso), siendo 3.36 GB (en escala base decimal) o según los datos extraídos mediante python **3.13 gb** (en escala base binario)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una última métrica importante ha revisar es la suma del espacio asignado tanto a los documentos como a los índices en la colección. Es la suma de storageSize y indexSize. En el presente caso resultando un valor de **4.10 gb**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido       |\n",
    "|---------------------------------------------|----------------------|\n",
    "| Tiempo de carga                             | 3 h 12 min y 37.32 s |\n",
    "| Tamaño JSON bruto                           | 2.41 gb              |\n",
    "| Tamaño de almacenamiento en mongoDB         | 0.97 gb              |\n",
    "| Radio de compresión de documento            | 0.4017               |\n",
    "| Reducción de tamaño de memoria de documento | 59.83 %              |\n",
    "| Tamaño total de los índices                 | 3.13 gb              |\n",
    "| Tamaño total de almacenamiento colección    | 4.10 gb              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 1 millón de documentos y posterior indexación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga de 1 millón de documentos en una colección sin índices y el tamaño de almacenamiento de dicha cantidad de documentos una vez ya indexados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-mongo-no-index.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-mongo-no-index.py -n 1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El script antes mencionado recibe como entrada la cantidad de documentos que cargará a la base de datos. Secuencialmente, el código creará la nueva colección donde se cargarán los datos, cargará la información almacenada en un documento JSON de forma masiva, y creará finalmente los índices correspondientes a todos los campos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/load_1M_documentos_no_index_mongo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 1 millón de documentos sobre campos y posteriormente indexar todos los campos ha tomado un tiempo de **35.36 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en la colección ```extracto_cuenta_1m2``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 1000000 documentos en la colección 'extracto_cuenta_1m2'\n"
     ]
    }
   ],
   "source": [
    "cnt = db.extracto_cuenta_1m2.count_documents({})\n",
    "print(f\"Actualmente existen {cnt} documentos en la colección 'extracto_cuenta_1m2'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte de la colección ```extracto_cuenta_1m2``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"ns\": \"test_mongo.extracto_cuenta_1m2\",\n",
      " \"size\": 206123814,\n",
      " \"count\": 1000000,\n",
      " \"avgObjSize\": 206,\n",
      " \"numOrphanDocs\": 0,\n",
      " \"storageSize\": 100823040,\n",
      " \"freeStorageSize\": 0,\n",
      " \"capped\": false,\n",
      " \"wiredTiger\": {\n",
      "  \"metadata\": {\n",
      "   \"formatVersion\": 1\n",
      "  },\n",
      "  \"creationString\": \"access_pattern_hint=none,all\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "r = dumps(db.command(\n",
    "   {\n",
    "     \"collStats\": \"extracto_cuenta_1m2\",\n",
    "     \"scale\": 1\n",
    "   }\n",
    "), indent=1)\n",
    "\n",
    "print(r[:300])\n",
    "print(\"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por los datos recopilados anteriormente se sabe que 1 documento de 1 millón de registros con un peso en bruto de 247.70 mb (en escala binario), una vez comprimido en la base de datos, para esta prueba en particular es **96.15 mb** (en escala base binario). Esto nos da un radio de compresión de 0.3882 y una reducción de tamaño en memoria del 61.18%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/storage_compass_1M_documentos_no_index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la herramienta gráfica compass se puede ver un reporte de 100.82 MB (en escala base decimal) de tamaño de almacenamiento, lo cual convertido a escala binaria resulta en 96.15 mb, un número aproximado al obtenido mediante el script de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      " },\n",
      " \"indexBuilds\": [],\n",
      " \"totalIndexSize\": 128323584,\n",
      " \"totalSize\": 229146624,\n",
      " \"indexSizes\": {\n",
      "  \"_id_\": 10743808,\n",
      "  \"fecha_1\": 20262912,\n",
      "  \"agencia_1\": 5373952,\n",
      "  \"monto_1\": 16683008,\n",
      "  \"saldo_1\": 18006016,\n",
      "  \"descripcion_1\": 5603328,\n",
      "  \"nota_1\": 51650560\n",
      " },\n",
      " \"scaleFactor\": 1,\n",
      " \"ok\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"...\")\n",
    "print(r[109788:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante que se meustra en compass es el tamaño total de los índices (7 índices en este caso), siendo 128.32 MB (en escala base decimal) o según los datos extraídos mediante python **122.37 mb** (en escala base binario)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una última métrica importante ha revisar es la suma del espacio asignado tanto a los documentos como a los índices en la colección. Es la suma de storageSize y indexSize. En el presente caso resultando un valor de **218.53 mb**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido |\n",
    "|---------------------------------------------|----------------|\n",
    "| Tiempo de carga                             | 35.36 s        |\n",
    "| Tamaño JSON bruto                           | 247.70 mb      |\n",
    "| Tamaño de almacenamiento en mongoDB         | 96.15 mb       |\n",
    "| Radio de compresión de documento            | 0.3882         |\n",
    "| Reducción de tamaño de memoria de documento | 61.18 %        |\n",
    "| Tamaño total de los índices                 | 122.37 mb      |\n",
    "| Tamaño total de almacenamiento colección    | 218.53 mb      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 10 millones de documentos y posterior indexación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga de 10 millones de documentos en una colección sin índices y el tamaño de almacenamiento de dicha cantidad de documentos una vez ya indexados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-mongo-no-index.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-mongo-no-index.py -n 10\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El script antes mencionado recibe como entrada la cantidad de documentos que cargará a la base de datos. Secuencialmente, el código creará la nueva colección donde se cargarán los datos, cargará la información almacenada en un documento JSON de forma masiva, y creará finalmente los índices correspondientes a todos los campos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/load_10M_documentos_no_index_mongo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 10 millones de documentos sobre campos y posteriormente indexar todos los campos ha tomado un tiempo de **7 minutos 1.82 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en la colección ```extracto_cuenta_10m2``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 1000000 documentos en la colección 'extracto_cuenta_10m2'\n"
     ]
    }
   ],
   "source": [
    "cnt = db.extracto_cuenta_10m2.count_documents({})\n",
    "print(f\"Actualmente existen {cnt} documentos en la colección 'extracto_cuenta_10m2'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte de la colección ```extracto_cuenta_10m2``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"ns\": \"test_mongo.extracto_cuenta_10m2\",\n",
      " \"size\": 2061015647,\n",
      " \"count\": 10000000,\n",
      " \"avgObjSize\": 206,\n",
      " \"numOrphanDocs\": 0,\n",
      " \"storageSize\": 1004490752,\n",
      " \"freeStorageSize\": 2162688,\n",
      " \"capped\": false,\n",
      " \"wiredTiger\": {\n",
      "  \"metadata\": {\n",
      "   \"formatVersion\": 1\n",
      "  },\n",
      "  \"creationString\": \"access_pattern_hin\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "r = dumps(db.command(\n",
    "   {\n",
    "     \"collStats\": \"extracto_cuenta_10m2\",\n",
    "     \"scale\": 1\n",
    "   }\n",
    "), indent=1)\n",
    "\n",
    "print(r[:300])\n",
    "print(\"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tamaño de almacenamiento de 10 documentos de 1 millón de registros con un peso en total en bruto de 2.41 gb (en escala base binario), una vez comprimido en la base de datos es **0.93 gb** (en escala base binario). Esto nos da un radio de compresión de 0.3868 y una reducción de tamaño en memoria del 61.32%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/storage_compass_10M_documentos_no_index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la herramienta gráfica compass se puede ver un reporte de 1.00 GB (en escala base decimal) de tamaño de almacenamiento, lo cual convertido a escala binaria resulta en 93.13 mb, un número aproximado al obtenido mediante el script de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      " },\n",
      " \"indexBuilds\": [],\n",
      " \"totalIndexSize\": 1226719232,\n",
      " \"totalSize\": 2231209984,\n",
      " \"indexSizes\": {\n",
      "  \"_id_\": 110129152,\n",
      "  \"fecha_1\": 186114048,\n",
      "  \"agencia_1\": 53514240,\n",
      "  \"monto_1\": 158367744,\n",
      "  \"saldo_1\": 173264896,\n",
      "  \"descripcion_1\": 55648256,\n",
      "  \"nota_1\": 489680896\n",
      " },\n",
      " \"scaleFactor\": 1,\n",
      " \"ok\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"...\")\n",
    "print(r[109935:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante que se meustra en compass es el tamaño total de los índices (7 índices en este caso), siendo 1.23 GB (en escala base decimal) o según los datos extraídos mediante python **1.14 gb** (en escala base binario)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una última métrica importante ha revisar es la suma del espacio asignado tanto a los documentos como a los índices en la colección. Es la suma de storageSize y indexSize. En el presente caso resultando un valor de **2.08 gb**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido |\n",
    "|---------------------------------------------|----------------|\n",
    "| Tiempo de carga                             | 7 min 1.82 s   |\n",
    "| Tamaño JSON bruto                           | 2.41 gb        |\n",
    "| Tamaño de almacenamiento en mongoDB         | 0.93 gb        |\n",
    "| Radio de compresión de documento            | 0.3868         |\n",
    "| Reducción de tamaño de memoria de documento | 61.32 %        |\n",
    "| Tamaño total de los índices                 | 1.14 gb        |\n",
    "| Tamaño total de almacenamiento colección    | 2.08 gb        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 30 millones de documentos y posterior indexación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga de 30 millones de documentos en una colección sin índices y el tamaño de almacenamiento de dicha cantidad de documentos una vez ya indexados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-mongo-no-index.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-mongo-no-index.py -n 30\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El script antes mencionado recibe como entrada la cantidad de documentos que cargará a la base de datos. Secuencialmente, el código creará la nueva colección donde se cargarán los datos, cargará la información almacenada en un documento JSON de forma masiva, y creará finalmente los índices correspondientes a todos los campos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/load_30M_documentos_mongo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 30 millones de documentos sobre campos y posteriormente indexar todos los campos ha tomado un tiempo de **37 minutos 31.62 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en la colección ```extracto_cuenta_30m``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 30000000 documentos en 'extracto_cuenta_30m'\n"
     ]
    }
   ],
   "source": [
    "cnt = db.extracto_cuenta_30m.count_documents({})\n",
    "print(f\"Actualmente existen {cnt} documentos en 'extracto_cuenta_30m'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar el tamaño de los archivos JSON en su forma bruta, antes de cargarse a la base de datos, se utilizará el siguiente script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento random-generated-data-1.json con tamaño en memoria de 259734499 bytes\n",
      "Documento random-generated-data-10.json con tamaño en memoria de 259687666 bytes\n",
      "Documento random-generated-data-11.json con tamaño en memoria de 259697531 bytes\n",
      "Documento random-generated-data-12.json con tamaño en memoria de 259660386 bytes\n",
      "Documento random-generated-data-13.json con tamaño en memoria de 259651170 bytes\n",
      "Documento random-generated-data-14.json con tamaño en memoria de 259696780 bytes\n",
      "Documento random-generated-data-15.json con tamaño en memoria de 259771941 bytes\n",
      "Documento random-generated-data-16.json con tamaño en memoria de 259765264 bytes\n",
      "Documento random-generated-data-17.json con tamaño en memoria de 259736398 bytes\n",
      "Documento random-generated-data-18.json con tamaño en memoria de 259722533 bytes\n",
      "Documento random-generated-data-19.json con tamaño en memoria de 259695669 bytes\n",
      "Documento random-generated-data-2.json con tamaño en memoria de 259739233 bytes\n",
      "Documento random-generated-data-20.json con tamaño en memoria de 259719008 bytes\n",
      "Documento random-generated-data-21.json con tamaño en memoria de 259769492 bytes\n",
      "Documento random-generated-data-22.json con tamaño en memoria de 259702477 bytes\n",
      "Documento random-generated-data-23.json con tamaño en memoria de 259717193 bytes\n",
      "Documento random-generated-data-24.json con tamaño en memoria de 259680473 bytes\n",
      "Documento random-generated-data-25.json con tamaño en memoria de 259720743 bytes\n",
      "Documento random-generated-data-26.json con tamaño en memoria de 259702629 bytes\n",
      "Documento random-generated-data-27.json con tamaño en memoria de 259688801 bytes\n",
      "Documento random-generated-data-28.json con tamaño en memoria de 259680429 bytes\n",
      "Documento random-generated-data-29.json con tamaño en memoria de 259690215 bytes\n",
      "Documento random-generated-data-3.json con tamaño en memoria de 259672974 bytes\n",
      "Documento random-generated-data-30.json con tamaño en memoria de 259711947 bytes\n",
      "Documento random-generated-data-4.json con tamaño en memoria de 259706379 bytes\n",
      "Documento random-generated-data-5.json con tamaño en memoria de 259739617 bytes\n",
      "Documento random-generated-data-6.json con tamaño en memoria de 259653811 bytes\n",
      "Documento random-generated-data-7.json con tamaño en memoria de 259684247 bytes\n",
      "Documento random-generated-data-8.json con tamaño en memoria de 259721647 bytes\n",
      "Documento random-generated-data-9.json con tamaño en memoria de 259717709 bytes\n",
      "\n",
      "Sumando un total de 7791238861 bytes\n"
     ]
    }
   ],
   "source": [
    "file_sizes = []\n",
    "file_names = []\n",
    "sum = 0\n",
    "\n",
    "n = 30\n",
    "\n",
    "for i, json_file in enumerate(sorted(os.listdir(\"../json-generated-data\"))):\n",
    "    file_stat = os.stat(os.path.join(\"../json-generated-data\", json_file))\n",
    "    file_sizes.append(file_stat)\n",
    "    file_names.append(json_file)\n",
    "    sum = sum + int(file_stat.st_size)\n",
    "    \n",
    "    if i+1 == n:\n",
    "        break\n",
    "\n",
    "for file, f_name in zip(file_sizes, file_names):\n",
    "    print(f'Documento {f_name} con tamaño en memoria de {file.st_size} bytes')\n",
    "\n",
    "print(\"\")\n",
    "print(f'Sumando un total de {sum} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte de la colección ```extracto_cuenta_30m``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"ns\": \"test_mongo.extracto_cuenta_30m\",\n",
      " \"size\": 6182911222,\n",
      " \"count\": 30000000,\n",
      " \"avgObjSize\": 206,\n",
      " \"numOrphanDocs\": 0,\n",
      " \"storageSize\": 2984677376,\n",
      " \"freeStorageSize\": 954368,\n",
      " \"capped\": false,\n",
      " \"wiredTiger\": {\n",
      "  \"metadata\": {\n",
      "   \"formatVersion\": 1\n",
      "  },\n",
      "  \"creationString\": \"access_pattern_hint=\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "r = dumps(db.command(\n",
    "   {\n",
    "     \"collStats\": \"extracto_cuenta_30m\",\n",
    "     \"scale\": 1\n",
    "   }\n",
    "), indent=1)\n",
    "\n",
    "print(r[:300])\n",
    "print(\"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tamaño de almacenamiento de 30 documentos de 1 millón de registros con un peso en total en bruto de 7.26 gb (en escala base binario), una vez comprimido en la base de datos es **2.78 gb** (en escala base binario). Esto nos da un radio de compresión de 0.3830 y una reducción de tamaño en memoria del 61.69%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/mongo-insert/storage_compass_30M_documentos_no_index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la herramienta gráfica compass se puede ver un reporte de 2.98 GB (en escala base decimal) de tamaño de almacenamiento, lo cual convertido a escala binaria resulta en 2.78 gb, un número aproximado al obtenido mediante el script de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\n",
      " },\n",
      " \"indexBuilds\": [],\n",
      " \"totalIndexSize\": 3570143232,\n",
      " \"totalSize\": 6554820608,\n",
      " \"indexSizes\": {\n",
      "  \"_id_\": 331038720,\n",
      "  \"fecha_1\": 512319488,\n",
      "  \"agencia_1\": 160526336,\n",
      "  \"monto_1\": 468492288,\n",
      "  \"saldo_1\": 493805568,\n",
      "  \"descripcion_1\": 166879232,\n",
      "  \"nota_1\": 1437081600\n",
      " },\n",
      " \"scaleFactor\": 1,\n",
      " \"ok\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"...\")\n",
    "print(r[109750:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante que se meustra en compass es el tamaño total de los índices (7 índices en este caso), siendo 3.32 GB (en escala base decimal) o según los datos extraídos mediante python **3.32 gb** (en escala base binario)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una última métrica importante ha revisar es la suma del espacio asignado tanto a los documentos como a los índices en la colección. Es la suma de storageSize y indexSize. En el presente caso resultando un valor de **6.10 gb**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido |\n",
    "|---------------------------------------------|----------------|\n",
    "| Tiempo de carga                             | 37 min 31.62 s |\n",
    "| Tamaño JSON bruto                           | 7.26 gb        |\n",
    "| Tamaño de almacenamiento en mongoDB         | 2.68 gb        |\n",
    "| Radio de compresión de documento            | 0.3830         |\n",
    "| Reducción de tamaño de memoria de documento | 61.69 %        |\n",
    "| Tamaño total de los índices                 | 3.32 gb        |\n",
    "| Tamaño total de almacenamiento colección    | 6.10 gb        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 10 millones de documentos y posterior indexación (solo 3 campos: fecha, descripción, nota)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga de 10 millones de documentos en una colección sin índices y el tamaño de almacenamiento de dicha cantidad de documentos una vez ya indexados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-mongo-3-index.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-mongo-3-index.py -n 10\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El script antes mencionado recibe como entrada la cantidad de documentos que cargará a la base de datos. Secuencialmente, el código creará la nueva colección donde se cargarán los datos, cargará la información almacenada en un documento JSON de forma masiva, y creará finalmente los índices correspondientes a los campos: fecha, descripción y nota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../imagenes-de-soporte/mongo-insert/load_10M_documentos_3_index_mongo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 10 millones de documentos y posteriormente indexar todos los campos ha tomado un tiempo de **6 minutos 4.71 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en la colección ```extracto_cuenta_10_3idx``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 10000000 documentos en la colección 'extracto_cuenta_10_3idx'\n"
     ]
    }
   ],
   "source": [
    "cnt = db.extracto_cuenta_10_3idx.count_documents({})\n",
    "print(f\"Actualmente existen {cnt} documentos en la colección 'extracto_cuenta_10_3idx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte de la colección ```extracto_cuenta_10_3idx``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"ns\": \"test_mongo.extracto_cuenta_10m_3idx\",\n",
      " \"size\": 2061015647,\n",
      " \"count\": 10000000,\n",
      " \"avgObjSize\": 206,\n",
      " \"numOrphanDocs\": 0,\n",
      " \"storageSize\": 1001488384,\n",
      " \"freeStorageSize\": 2146304,\n",
      " \"capped\": false,\n",
      " \"wiredTiger\": {\n",
      "  \"metadata\": {\n",
      "   \"formatVersion\": 1\n",
      "  },\n",
      "  \"creationString\": \"access_pattern\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "r = dumps(db.command(\n",
    "   {\n",
    "     \"collStats\": \"extracto_cuenta_10m_3idx\",\n",
    "     \"scale\": 1\n",
    "   }\n",
    "), indent=1)\n",
    "\n",
    "print(r[:300])\n",
    "print(\"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tamaño de almacenamiento de 10 documentos de 1 millón de registros con un peso en total en bruto de 2.41 gb (en escala base binario), una vez comprimido en la base de datos es **0.93 gb** (en escala base binario). Esto nos da un radio de compresión de 0.3856 y una reducción de tamaño en memoria del 61.44%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../imagenes-de-soporte/mongo-insert/storage_compass_10M_documentos_3_index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la herramienta gráfica compass se puede ver un reporte de 0.99 GB (en escala base decimal) de tamaño de almacenamiento, lo cual convertido a escala binaria resulta en 0.93 gb, un número aproximado al obtenido mediante el script de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "},\n",
      " \"indexBuilds\": [],\n",
      " \"totalIndexSize\": 841588736,\n",
      " \"totalSize\": 1843077120,\n",
      " \"indexSizes\": {\n",
      "  \"_id_\": 110145536,\n",
      "  \"fecha_1\": 186114048,\n",
      "  \"descripcion_1\": 55648256,\n",
      "  \"nota_1\": 489680896\n",
      " },\n",
      " \"scaleFactor\": 1,\n",
      " \"ok\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"...\")\n",
    "print(r[(len(r)-227):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante que se meustra en compass es el tamaño total de los índices (3 índices en este caso), siendo 0.84 GB (en escala base decimal) o según los datos extraídos mediante python **0.78 gb** (en escala base binario)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una última métrica importante ha revisar es la suma del espacio asignado tanto a los documentos como a los índices en la colección. Es la suma de storageSize y indexSize. En el presente caso resultando un valor de **1.72 gb**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido |\n",
    "|---------------------------------------------|----------------|\n",
    "| Tiempo de carga                             | 6 min 4.71 s   |\n",
    "| Tamaño JSON bruto                           | 2.41 gb        |\n",
    "| Tamaño de almacenamiento en mongoDB         | 0.93 gb        |\n",
    "| Radio de compresión de documento            | 0.3856         |\n",
    "| Reducción de tamaño de memoria de documento | 61.44 %        |\n",
    "| Tamaño total de los índices                 | 0.78 gb        |\n",
    "| Tamaño total de almacenamiento colección    | 1.72 gb        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 30 millones de documentos y posterior indexación (solo 3 campos: fecha, descripción, nota)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga de 30 millones de documentos en una colección sin índices y el tamaño de almacenamiento de dicha cantidad de documentos una vez ya indexados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-mongo-3-index.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-mongo-3-index.py -n 30\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El script antes mencionado recibe como entrada la cantidad de documentos que cargará a la base de datos. Secuencialmente, el código creará la nueva colección donde se cargarán los datos, cargará la información almacenada en un documento JSON de forma masiva, y creará finalmente los índices correspondientes a los campos: fecha, descripción y nota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../imagenes-de-soporte/mongo-insert/load_30M_documentos_3_index_mongo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 10 millones de documentos y posteriormente indexar todos los campos ha tomado un tiempo de **21 minutos 41.49 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en la colección ```extracto_cuenta_30_3idx``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 30000000 documentos en la colección 'extracto_cuenta_30m_3idx'\n"
     ]
    }
   ],
   "source": [
    "cnt = db.extracto_cuenta_30m_3idx.count_documents({})\n",
    "print(f\"Actualmente existen {cnt} documentos en la colección 'extracto_cuenta_30m_3idx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte de la colección ```extracto_cuenta_30_3idx``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"ns\": \"test_mongo.extracto_cuenta_30m_3idx\",\n",
      " \"size\": 6182911222,\n",
      " \"count\": 30000000,\n",
      " \"avgObjSize\": 206,\n",
      " \"numOrphanDocs\": 0,\n",
      " \"storageSize\": 3045593088,\n",
      " \"freeStorageSize\": 2899968,\n",
      " \"capped\": false,\n",
      " \"wiredTiger\": {\n",
      "  \"metadata\": {\n",
      "   \"formatVersion\": 1\n",
      "  },\n",
      "  \"creationString\": \"access_pattern\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "r = dumps(db.command(\n",
    "   {\n",
    "     \"collStats\": \"extracto_cuenta_30m_3idx\",\n",
    "     \"scale\": 1\n",
    "   }\n",
    "), indent=1)\n",
    "\n",
    "print(r[:300])\n",
    "print(\"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tamaño de almacenamiento de 30 documentos de 1 millón de registros con un peso en total en bruto de 7.26 gb (en escala base binario), una vez comprimido en la base de datos es **2.84 gb** (en escala base binario). Esto nos da un radio de compresión de 0.3908 y una reducción de tamaño en memoria del 60.91%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../imagenes-de-soporte/mongo-insert/storage_compass_30M_documentos_3_index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante la herramienta gráfica compass se puede ver un reporte de 3.04 GB (en escala base decimal) de tamaño de almacenamiento, lo cual convertido a escala binaria resulta en 2.83 gb, un número aproximado al obtenido mediante el script de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "},\n",
      " \"indexBuilds\": [],\n",
      " \"totalIndexSize\": 2448347136,\n",
      " \"totalSize\": 5493940224,\n",
      " \"indexSizes\": {\n",
      "  \"_id_\": 332066816,\n",
      "  \"fecha_1\": 512319488,\n",
      "  \"descripcion_1\": 166879232,\n",
      "  \"nota_1\": 1437081600\n",
      " },\n",
      " \"scaleFactor\": 1,\n",
      " \"ok\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"...\")\n",
    "print(r[(len(r)-230):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante que se meustra en compass es el tamaño total de los índices (3 índices en este caso), siendo 2.45 GB (en escala base decimal) o según los datos extraídos mediante python **2.28 gb** (en escala base binario)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una última métrica importante ha revisar es la suma del espacio asignado tanto a los documentos como a los índices en la colección. Es la suma de storageSize y indexSize. En el presente caso resultando un valor de **5.12 gb**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido |\n",
    "|---------------------------------------------|----------------|\n",
    "| Tiempo de carga                             | 21 min 41.49 s |\n",
    "| Tamaño JSON bruto                           | 7.26 gb        |\n",
    "| Tamaño de almacenamiento en mongoDB         | 2.84 gb        |\n",
    "| Radio de compresión de documento            | 0.3908         |\n",
    "| Reducción de tamaño de memoria de documento | 60.91 %        |\n",
    "| Tamaño total de los índices                 | 2.28 gb        |\n",
    "| Tamaño total de almacenamiento colección    | 5.12 gb        |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7e5a1f785ed82844e2da5d30522181462e1597dbd1807cbc4c5c0cc1d5a2e0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
