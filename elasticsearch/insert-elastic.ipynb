{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id1' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to ElasticSearch cluster `docker-cluster`\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from json import dumps\n",
    "from random import randrange, choice, uniform\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "from random import randint\n",
    "from lorem_text import lorem\n",
    "import os\n",
    "from numpy import asarray, mean\n",
    "\n",
    "es = Elasticsearch(\"http://127.0.0.1:9200\")\n",
    "\n",
    "print(f\"Connected to ElasticSearch cluster `{es.info().body['cluster_name']}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='id2' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de documentos individualmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará el tiempo de carga de 10 000 documentos que serán generados aleatoriamente y posteriormente serán cargados de manera individual secuencialmente a la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de datos aleatorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La celda a continuación muestra el script usado para generar los datos aleatorios. Un código similar será incluido en el script será utilizado para generar los documentos JSON que se utilizarán en las siguientes secciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_date(start, end):\n",
    "    delta = end - start\n",
    "    int_delta = (delta.days * 24 * 60 * 60) + delta.seconds\n",
    "    random_second = randrange(int_delta)\n",
    "    return start + timedelta(seconds=random_second)\n",
    "\n",
    "d1 = datetime.strptime('1/1/1950 12:59 PM', '%m/%d/%Y %I:%M %p')\n",
    "d2 = datetime.strptime('1/1/2022 01:00 AM', '%m/%d/%Y %I:%M %p')\n",
    "\n",
    "descripciones = [\n",
    "    'Transferencia interbancaria SIMPLE',\n",
    "    'DEB.CTA.P/C.INTERNET',\n",
    "    'Debito Cta por ACH',\n",
    "    'Retiro en efectivo',\n",
    "    'AB.CTA.P/MOVIL',\n",
    "    'Pago recibo de agua',\n",
    "    'Debito Cta por compra',\n",
    "    'Debito Cta por pago de Seguro',\n",
    "    'Retención IVA',\n",
    "    'Cargo por cobro de servicio',\n",
    "    'Cobro seguro',\n",
    "    'Intereses',\n",
    "    'Ingreso en efectivo',\n",
    "    'Reintegro cajero automático',\n",
    "    'Pago de cheque compensado',\n",
    "    'Pago recibo de luz',\n",
    "    'Deposito a cuenta',\n",
    "    'Comisión de mantenimiento',\n",
    "    'Pago en interés',\n",
    "    'Consignación en efectivo',\n",
    "    'Pago recibo de gas',\n",
    "    'Compra en comercio',\n",
    "    'Apertura de cuenta corriente',\n",
    "    'Pago de nómina',\n",
    "    'Capitalización de intereses premio',\n",
    "    'Aporte inversor',\n",
    "    'Pago de servicio telefónico',\n",
    "    'Transferencia de fondos de ahorros',\n",
    "    'Pago en línea - Servicio de internet',\n",
    "    'Apertura de caja de ahorros'\n",
    "]\n",
    "\n",
    "agencias = ['La Paz',\n",
    "            'Oruro', \n",
    "            'Cochabamba', \n",
    "            'Chuquisaca', \n",
    "            'Pando', \n",
    "            'Beni', \n",
    "            'Santa Cruz', \n",
    "            'Tarija'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de índices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La celda a continuación muestra el script usado para crear los índices de los campos. Un código similar será incluido en el script será utilizado para cargar los documentos a la base de datos en las siguientes secciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "        \"properties\": {\n",
    "            \"fecha\": {\n",
    "                \"type\": \"date\",\n",
    "                \"format\": \"yyyy-MM-dd HH:mm:ss\"\n",
    "            },\n",
    "            \"agencia\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"monto\": {\n",
    "                \"type\": \"float\"\n",
    "            },\n",
    "            \"descripcion\": {\n",
    "                \"type\": \"text\"\n",
    "            },\n",
    "            \"saldo\": {\n",
    "                \"type\": \"float\"\n",
    "            },\n",
    "            \"nota\": {\n",
    "                \"type\": \"text\"\n",
    "            }\n",
    "        }\n",
    "}   \n",
    "\n",
    "response = es.indices.create(\n",
    "    index=\"extracto_cuenta_seq\",\n",
    "    mappings = mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de 10 000 registros de forma individual secuencialmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el script a continuación se cargarán 10 000 registros generados aleatoriamente de manera individual y secuencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo promedio de carga de un solo documento: 0:00:00.173490\n",
      "Tiempo de carga de datos: 0:28:55.780249\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "time_insert_one = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    fecha = str(random_date(d1, d2))\n",
    "    agencia = choice(agencias)\n",
    "    monto = round(uniform(10.0, 400000.0), 2)\n",
    "    descripcion = choice(descripciones)\n",
    "    saldo = round(uniform(0.0, 10000000.0), 2)\n",
    "    nota = lorem.words(randint(1,13))\n",
    "\n",
    "    insert_data = {\n",
    "        'fecha': fecha,\n",
    "        'agencia': agencia,\n",
    "        'monto': monto,\n",
    "        'descripcion': descripcion,\n",
    "        'saldo': saldo,\n",
    "        'nota': nota\n",
    "    }\n",
    "\n",
    "    one_start_time = time.time()\n",
    "    es.index(index=\"extracto_cuenta_seq\", document=insert_data)\n",
    "    one_end_time = time.time()\n",
    "\n",
    "    time_insert_one.append(one_end_time-one_start_time)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "avg_insert_one_time = mean(asarray(time_insert_one))\n",
    "\n",
    "# Mostramos los resultados en consola\n",
    "\n",
    "print(f'Tiempo promedio de carga de un solo documento: {str(timedelta(seconds = avg_insert_one_time))}')\n",
    "print(f'Tiempo de carga de datos: {str(timedelta(seconds = (end_time - start_time)))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según muestran los resultados de ejecución de la celda superior, se tiene un tiempo promedio de carga por documento de **0.17 segundos**, y un tiempo total de carga del total de 10 000 documentos de **28 minutos y 55.78 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en el índice ```extracto_cuenta_seq``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 10 documentos en el índice 'extracto_cuenta_seq'\n"
     ]
    }
   ],
   "source": [
    "cnt = es.cat.count(index=\"extracto_cuenta_seq\", format= \"json\")[0]['count']\n",
    "print(f\"Actualmente existen {cnt} documentos en el índice 'extracto_cuenta_seq'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 1 millón de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga y el tamaño de almacenamiento de 1 millón de documentos indexados en la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-elastic.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-elastic.py -n 1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/elastic-insert/load_1M_documents_elastic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 1 millón de documentos ha tomado un tiempo de **4 minutos y 26.16 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en el índice ```extracto_cuenta_1m``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 1000000 documentos en el índice 'extracto_cuenta_1m'\n"
     ]
    }
   ],
   "source": [
    "cnt = es.cat.count(index=\"extracto_cuenta_1m\", format= \"json\")[0]['count']\n",
    "print(f\"Actualmente existen {cnt} documentos en el índice 'extracto_cuenta_1m'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar el tamaño de los archivos JSON en su forma bruta, antes de cargarse a la base de datos, se utilizará el siguiente script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento random-generated-data-1.json con tamaño en memoria de 188495887 bytes\n"
     ]
    }
   ],
   "source": [
    "file_sizes = []\n",
    "n = 1\n",
    "\n",
    "for i, json_file in enumerate(sorted(os.listdir(\"../json-generated-data-elastic\"))):\n",
    "    file_stat = os.stat(os.path.join(\"../json-generated-data-elastic\", json_file))\n",
    "    file_sizes.append(file_stat)\n",
    "\n",
    "    if i+1 == n:\n",
    "        break\n",
    "\n",
    "for file in file_sizes:\n",
    "    print(f'Documento {json_file} con tamaño en memoria de {file.st_size} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte del índice ```extracto_cuenta_1m``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"store_size\": \"138.3mb\",\n",
      " \"store_size_in_bytes\": 145089787,\n",
      " \"all_fields\": {\n",
      "  \"total\": \"137.5mb\",\n",
      "  \"total_in_bytes\": 144187007,\n",
      "  \"inverted_index\": {\n",
      "   \"total\": \"19mb\",\n",
      "   \"total_in_bytes\": 19932341\n",
      "  },\n",
      "  \"stored_fields\": \"87.7mb\",\n",
      "  \"stored_fields_in_bytes\": 91994865,\n",
      "  \"doc_values\": \"12.8mb\",\n",
      "  \"doc_values_in_bytes\": 13503952,\n",
      "  \"points\": \"15.9mb\",\n",
      "  \"points_in_bytes\": 16755849,\n",
      "  \"norms\": \"1.9mb\",\n",
      "  \"norms_in_bytes\": 2000000,\n",
      "  \"term_vectors\": \"0b\",\n",
      "  \"term_vectors_in_bytes\": 0,\n",
      "  \"knn_vectors\": \"0b\",\n",
      "  \"knn_vectors_in_bytes\": 0\n",
      " },\n",
      " \"fields\": {\n",
      "  \"_id\": {\n",
      "   \"total\": \"15.5mb\",\n",
      "   \"total_in_bytes\": 16300151,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"5.1mb\",\n",
      "    \"total_in_bytes\": 5348000\n",
      "   },\n",
      "   \"stored_fields\": \"10.4mb\",\n",
      "   \"stored_fields_in_bytes\": 10952151,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_primary_term\": {\n",
      "   \"total\": \"0b\",\n",
      "   \"total_in_bytes\": 0,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_seq_no\": {\n",
      "   \"total\": \"2.9mb\",\n",
      "   \"total_in_bytes\": 3097883,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"1.9mb\",\n",
      "   \"doc_values_in_bytes\": 2003157,\n",
      "   \"points\": \"1mb\",\n",
      "   \"points_in_bytes\": 1094726,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_source\": {\n",
      "   \"total\": \"77.2mb\",\n",
      "   \"total_in_bytes\": 81042714,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"77.2mb\",\n",
      "   \"stored_fields_in_bytes\": 81042714,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_version\": {\n",
      "   \"total\": \"0b\",\n",
      "   \"total_in_bytes\": 0,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"agencia\": {\n",
      "   \"total\": \"1.1mb\",\n",
      "   \"total_in_bytes\": 1201839,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"684.6kb\",\n",
      "    \"total_in_bytes\": 701046\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"489kb\",\n",
      "   \"doc_values_in_bytes\": 500793,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"descripcion\": {\n",
      "   \"total\": \"4.2mb\",\n",
      "   \"total_in_bytes\": 4405333,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"3.2mb\",\n",
      "    \"total_in_bytes\": 3405333\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"976.5kb\",\n",
      "   \"norms_in_bytes\": 1000000,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"fecha\": {\n",
      "   \"total\": \"10mb\",\n",
      "   \"total_in_bytes\": 10589271,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"3.8mb\",\n",
      "   \"doc_values_in_bytes\": 4000000,\n",
      "   \"points\": \"6.2mb\",\n",
      "   \"points_in_bytes\": 6589271,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"monto\": {\n",
      "   \"total\": \"7.6mb\",\n",
      "   \"total_in_bytes\": 8033172,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"3.3mb\",\n",
      "   \"doc_values_in_bytes\": 3500001,\n",
      "   \"points\": \"4.3mb\",\n",
      "   \"points_in_bytes\": 4533171,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"nota\": {\n",
      "   \"total\": \"10.9mb\",\n",
      "   \"total_in_bytes\": 11477962,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"9.9mb\",\n",
      "    \"total_in_bytes\": 10477962\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"976.5kb\",\n",
      "   \"norms_in_bytes\": 1000000,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"saldo\": {\n",
      "   \"total\": \"7.6mb\",\n",
      "   \"total_in_bytes\": 8038682,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"3.3mb\",\n",
      "   \"doc_values_in_bytes\": 3500001,\n",
      "   \"points\": \"4.3mb\",\n",
      "   \"points_in_bytes\": 4538681,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  }\n",
      " }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r = dumps(es.indices.disk_usage(index=\"extracto_cuenta_1m\", run_expensive_tasks=True)['extracto_cuenta_1m'], indent=1)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrayendo información importante de los datos recién obtenidos. El tamaño en almacenamiento aproximado de 1 documento de 1 millón de registros con un peso en bruto de 179.76 mb (en escala base binario $2^{20}$), una vez cargado en la base de datos es **77.28 mb** (en escala base binario). Esto nos da un radio de compresión de 0.4299 y una reducción de tamaño en memoria del 57.01%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante al que se le debe prestar atención es el tamaño de los índices en memoria, reportando en el presente caso un tamaño total de todos los índices de **57.26 mb** (en escala base binario). Otro número presente en el reporte de uso de almacenamiento es el número de secuencia, encargado de contar el número de operaciones realizadas en el índice, con un tamaño de **2.95 mb** (en escala base binario). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumando el tamaño de almacenamiento de los documentos, el total de los índices y otros números relevantes, se alcanza un tamaño de almacenamiento en memoria total de **137.51 mb** (en escala base binario)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/elastic-insert/storage_kibana_1M_documents.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la figura superior podemos ver que la herramienta gráfica Kibana índica un tamaño de almacenamiento total de **138.37 mb**, número ligeramente mayor al calculado anteriormente, ya que podrían estarse ignorando algunos metadatos pequeños."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido |\n",
    "|---------------------------------------------|----------------|\n",
    "| Tiempo de carga                             | 4 min 26.16 s  |\n",
    "| Tamaño JSON bruto                           | 179.76 mb      |\n",
    "| Tamaño de almacenamiento en elasticsearch   | 77.28 mb       |\n",
    "| Radio de compresión de documento            | 0.4299         |\n",
    "| Reducción de tamaño de memoria de documento | 57.01 %        |\n",
    "| Tamaño total de los índices                 | 57.26 mb       |\n",
    "| Tamaño de número de secuencia               | 2.95 mb        |\n",
    "| Tamaño total de almacenamiento colección    | 137.51 mb      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 10 millones de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga y el tamaño de almacenamiento de 10 millones de documentos indexados en la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-elastic.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-elastic.py -n 10\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/elastic-insert/load_10M_documents_elastic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 10 millones de documentos ha tomado un tiempo de **48 minutos y 52.61 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en el índice ```extracto_cuenta_10m``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 10000000 documentos en el índice 'extracto_cuenta_10m'\n"
     ]
    }
   ],
   "source": [
    "cnt = es.cat.count(index=\"extracto_cuenta_10m\", format= \"json\")[0]['count']\n",
    "print(f\"Actualmente existen {cnt} documentos en el índice 'extracto_cuenta_10m'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar el tamaño de los archivos JSON en su forma bruta, antes de cargarse a la base de datos, se utilizará el siguiente script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento random-generated-data-1.json con tamaño en memoria de 188495887 bytes\n",
      "Documento random-generated-data-10.json con tamaño en memoria de 188447726 bytes\n",
      "Documento random-generated-data-11.json con tamaño en memoria de 188458209 bytes\n",
      "Documento random-generated-data-12.json con tamaño en memoria de 188418922 bytes\n",
      "Documento random-generated-data-13.json con tamaño en memoria de 188411232 bytes\n",
      "Documento random-generated-data-14.json con tamaño en memoria de 188458816 bytes\n",
      "Documento random-generated-data-15.json con tamaño en memoria de 188533759 bytes\n",
      "Documento random-generated-data-16.json con tamaño en memoria de 188525970 bytes\n",
      "Documento random-generated-data-17.json con tamaño en memoria de 188498006 bytes\n",
      "Documento random-generated-data-18.json con tamaño en memoria de 188480785 bytes\n",
      "\n",
      "Sumando un total de 1884729312 bytes\n"
     ]
    }
   ],
   "source": [
    "file_sizes = []\n",
    "file_names = []\n",
    "sum = 0\n",
    "\n",
    "n = 10\n",
    "\n",
    "for i, json_file in enumerate(sorted(os.listdir(\"../json-generated-data-elastic\"))):\n",
    "    file_stat = os.stat(os.path.join(\"../json-generated-data-elastic\", json_file))\n",
    "    file_sizes.append(file_stat)\n",
    "    file_names.append(json_file)\n",
    "    sum += int(file_stat.st_size)\n",
    "\n",
    "    if i+1 == n:\n",
    "        break\n",
    "\n",
    "for file, f_name in zip(file_sizes, file_names):\n",
    "    print(f'Documento {f_name} con tamaño en memoria de {file.st_size} bytes')\n",
    "\n",
    "print(\"\")\n",
    "print(f'Sumando un total de {sum} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte del índice ```extracto_cuenta_10m``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"store_size\": \"1.3gb\",\n",
      " \"store_size_in_bytes\": 1440202391,\n",
      " \"all_fields\": {\n",
      "  \"total\": \"1.3gb\",\n",
      "  \"total_in_bytes\": 1438808499,\n",
      "  \"inverted_index\": {\n",
      "   \"total\": \"191.3mb\",\n",
      "   \"total_in_bytes\": 200694994\n",
      "  },\n",
      "  \"stored_fields\": \"876.7mb\",\n",
      "  \"stored_fields_in_bytes\": 919322081,\n",
      "  \"doc_values\": \"128.7mb\",\n",
      "  \"doc_values_in_bytes\": 135007131,\n",
      "  \"points\": \"156.1mb\",\n",
      "  \"points_in_bytes\": 163784293,\n",
      "  \"norms\": \"19mb\",\n",
      "  \"norms_in_bytes\": 20000000,\n",
      "  \"term_vectors\": \"0b\",\n",
      "  \"term_vectors_in_bytes\": 0,\n",
      "  \"knn_vectors\": \"0b\",\n",
      "  \"knn_vectors_in_bytes\": 0\n",
      " },\n",
      " \"fields\": {\n",
      "  \"_id\": {\n",
      "   \"total\": \"158.1mb\",\n",
      "   \"total_in_bytes\": 165840919,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"53.5mb\",\n",
      "    \"total_in_bytes\": 56149847\n",
      "   },\n",
      "   \"stored_fields\": \"104.6mb\",\n",
      "   \"stored_fields_in_bytes\": 109691072,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_primary_term\": {\n",
      "   \"total\": \"0b\",\n",
      "   \"total_in_bytes\": 0,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_seq_no\": {\n",
      "   \"total\": \"29.1mb\",\n",
      "   \"total_in_bytes\": 30612012,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"19mb\",\n",
      "   \"doc_values_in_bytes\": 20005739,\n",
      "   \"points\": \"10.1mb\",\n",
      "   \"points_in_bytes\": 10606273,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_source\": {\n",
      "   \"total\": \"772.1mb\",\n",
      "   \"total_in_bytes\": 809631009,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"772.1mb\",\n",
      "   \"stored_fields_in_bytes\": 809631009,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_version\": {\n",
      "   \"total\": \"0b\",\n",
      "   \"total_in_bytes\": 0,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"agencia\": {\n",
      "   \"total\": \"11.4mb\",\n",
      "   \"total_in_bytes\": 11987350,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"6.6mb\",\n",
      "    \"total_in_bytes\": 6985962\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"4.7mb\",\n",
      "   \"doc_values_in_bytes\": 5001388,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"descripcion\": {\n",
      "   \"total\": \"41.6mb\",\n",
      "   \"total_in_bytes\": 43674365,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"32.1mb\",\n",
      "    \"total_in_bytes\": 33674365\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"9.5mb\",\n",
      "   \"norms_in_bytes\": 10000000,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"fecha\": {\n",
      "   \"total\": \"99.6mb\",\n",
      "   \"total_in_bytes\": 104488478,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"38.1mb\",\n",
      "   \"doc_values_in_bytes\": 40000000,\n",
      "   \"points\": \"61.5mb\",\n",
      "   \"points_in_bytes\": 64488478,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"monto\": {\n",
      "   \"total\": \"75.6mb\",\n",
      "   \"total_in_bytes\": 79332149,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"33.3mb\",\n",
      "   \"doc_values_in_bytes\": 35000002,\n",
      "   \"points\": \"42.2mb\",\n",
      "   \"points_in_bytes\": 44332147,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"nota\": {\n",
      "   \"total\": \"108.6mb\",\n",
      "   \"total_in_bytes\": 113884820,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"99mb\",\n",
      "    \"total_in_bytes\": 103884820\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"9.5mb\",\n",
      "   \"norms_in_bytes\": 10000000,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"saldo\": {\n",
      "   \"total\": \"75.6mb\",\n",
      "   \"total_in_bytes\": 79357397,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"33.3mb\",\n",
      "   \"doc_values_in_bytes\": 35000002,\n",
      "   \"points\": \"42.3mb\",\n",
      "   \"points_in_bytes\": 44357395,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  }\n",
      " }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r = dumps(es.options(request_timeout=30).indices.disk_usage(index=\"extracto_cuenta_10m\", run_expensive_tasks=True)['extracto_cuenta_10m'], indent=1)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrayendo información importante de los datos recién obtenidos. El tamaño en almacenamiento aproximado de 10 documentos de 1 millón de registros con un peso en bruto de 1.75 gb (en escala base binario $2^{30}$), una vez cargado en la base de datos es **0.75 gb** (en escala base binario). Esto nos da un radio de compresión de 0.4296 y una reducción de tamaño en memoria del 57.04%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante al que se le debe prestar atención es el tamaño de los índices en memoria, reportando en el presente caso un tamaño total de todos los índices de **0.56 gb** (en escala base binario). Otro número presente en el reporte de uso de almacenamiento es el número de secuencia, encargado de contar el número de operaciones realizadas en el índice, con un tamaño de **0.028 gb** (en escala base binario). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumando el tamaño de almacenamiento de los documentos, el total de los índices y otros números relevantes, se alcanza un tamaño de almacenamiento en memoria total de **1.34 gb** (en escala base binario)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 10 millones de documentos](../imagenes-de-soporte/elastic-insert/storage_kibana_10M_documents.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido |\n",
    "|---------------------------------------------|----------------|\n",
    "| Tiempo de carga                             | 48 m  52.61 s  |\n",
    "| Tamaño JSON bruto                           | 1.75 gb        |\n",
    "| Tamaño de almacenamiento en elasticsearch   | 0.75 gb        |\n",
    "| Radio de compresión de documento            | 0.4296         |\n",
    "| Reducción de tamaño de memoria de documento | 57.04 %        |\n",
    "| Tamaño total de los índices                 | 0.56 gb        |\n",
    "| Tamaño de número de secuencia               | 0.028 gb       |\n",
    "| Tamaño total de almacenamiento colección    | 1.34 gb        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 30 millones de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga y el tamaño de almacenamiento de 10 millones de documentos indexados en la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-elastic.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-elastic.py -n 30\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 1 millón de documentos](../imagenes-de-soporte/elastic-insert/load_30M_documentos_elastic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 10 millones de documentos ha tomado un tiempo de **2 horas 43 minutos y 20.68 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en el índice ```extracto_cuenta_30m``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 30000000 documentos en el índice 'extracto_cuenta_30m'\n"
     ]
    }
   ],
   "source": [
    "cnt = es.cat.count(index=\"extracto_cuenta_30m\", format= \"json\")[0]['count']\n",
    "print(f\"Actualmente existen {cnt} documentos en el índice 'extracto_cuenta_30m'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar el tamaño de los archivos JSON en su forma bruta, antes de cargarse a la base de datos, se utilizará el siguiente script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento random-generated-data-1.json con tamaño en memoria de 188495887 bytes\n",
      "Documento random-generated-data-10.json con tamaño en memoria de 188447726 bytes\n",
      "Documento random-generated-data-11.json con tamaño en memoria de 188458209 bytes\n",
      "Documento random-generated-data-12.json con tamaño en memoria de 188418922 bytes\n",
      "Documento random-generated-data-13.json con tamaño en memoria de 188411232 bytes\n",
      "Documento random-generated-data-14.json con tamaño en memoria de 188458816 bytes\n",
      "Documento random-generated-data-15.json con tamaño en memoria de 188533759 bytes\n",
      "Documento random-generated-data-16.json con tamaño en memoria de 188525970 bytes\n",
      "Documento random-generated-data-17.json con tamaño en memoria de 188498006 bytes\n",
      "Documento random-generated-data-18.json con tamaño en memoria de 188480785 bytes\n",
      "Documento random-generated-data-19.json con tamaño en memoria de 188455315 bytes\n",
      "Documento random-generated-data-2.json con tamaño en memoria de 188498611 bytes\n",
      "Documento random-generated-data-20.json con tamaño en memoria de 188481332 bytes\n",
      "Documento random-generated-data-21.json con tamaño en memoria de 188532148 bytes\n",
      "Documento random-generated-data-22.json con tamaño en memoria de 188463235 bytes\n",
      "Documento random-generated-data-23.json con tamaño en memoria de 188476269 bytes\n",
      "Documento random-generated-data-24.json con tamaño en memoria de 188438797 bytes\n",
      "Documento random-generated-data-25.json con tamaño en memoria de 188482897 bytes\n",
      "Documento random-generated-data-26.json con tamaño en memoria de 188463141 bytes\n",
      "Documento random-generated-data-27.json con tamaño en memoria de 188448685 bytes\n",
      "Documento random-generated-data-28.json con tamaño en memoria de 188438595 bytes\n",
      "Documento random-generated-data-29.json con tamaño en memoria de 188449519 bytes\n",
      "Documento random-generated-data-3.json con tamaño en memoria de 188434038 bytes\n",
      "Documento random-generated-data-30.json con tamaño en memoria de 188472509 bytes\n",
      "Documento random-generated-data-4.json con tamaño en memoria de 188465141 bytes\n",
      "Documento random-generated-data-5.json con tamaño en memoria de 188499067 bytes\n",
      "Documento random-generated-data-6.json con tamaño en memoria de 188416807 bytes\n",
      "Documento random-generated-data-7.json con tamaño en memoria de 188443871 bytes\n",
      "Documento random-generated-data-8.json con tamaño en memoria de 188477999 bytes\n",
      "Documento random-generated-data-9.json con tamaño en memoria de 188480013 bytes\n",
      "\n",
      "Sumando un total de 5654047301 bytes\n"
     ]
    }
   ],
   "source": [
    "file_sizes = []\n",
    "file_names = []\n",
    "sum = 0\n",
    "\n",
    "n = 30\n",
    "\n",
    "for i, json_file in enumerate(sorted(os.listdir(\"../json-generated-data-elastic\"))):\n",
    "    file_stat = os.stat(os.path.join(\"../json-generated-data-elastic\", json_file))\n",
    "    file_sizes.append(file_stat)\n",
    "    file_names.append(json_file)\n",
    "    sum += int(file_stat.st_size)\n",
    "\n",
    "    if i+1 == n:\n",
    "        break\n",
    "\n",
    "for file, f_name in zip(file_sizes, file_names):\n",
    "    print(f'Documento {f_name} con tamaño en memoria de {file.st_size} bytes')\n",
    "\n",
    "print(\"\")\n",
    "print(f'Sumando un total de {sum} bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte del índice ```extracto_cuenta_30m``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"store_size\": \"4gb\",\n",
      " \"store_size_in_bytes\": 4312400348,\n",
      " \"all_fields\": {\n",
      "  \"total\": \"4gb\",\n",
      "  \"total_in_bytes\": 4310628281,\n",
      "  \"inverted_index\": {\n",
      "   \"total\": \"575.2mb\",\n",
      "   \"total_in_bytes\": 603210337\n",
      "  },\n",
      "  \"stored_fields\": \"2.5gb\",\n",
      "  \"stored_fields_in_bytes\": 2757840185,\n",
      "  \"doc_values\": \"386.5mb\",\n",
      "  \"doc_values_in_bytes\": 405357153,\n",
      "  \"points\": \"461.7mb\",\n",
      "  \"points_in_bytes\": 484220606,\n",
      "  \"norms\": \"57.2mb\",\n",
      "  \"norms_in_bytes\": 60000000,\n",
      "  \"term_vectors\": \"0b\",\n",
      "  \"term_vectors_in_bytes\": 0,\n",
      "  \"knn_vectors\": \"0b\",\n",
      "  \"knn_vectors_in_bytes\": 0\n",
      " },\n",
      " \"fields\": {\n",
      "  \"_id\": {\n",
      "   \"total\": \"475.9mb\",\n",
      "   \"total_in_bytes\": 499018536,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"162.2mb\",\n",
      "    \"total_in_bytes\": 170110453\n",
      "   },\n",
      "   \"stored_fields\": \"313.6mb\",\n",
      "   \"stored_fields_in_bytes\": 328908083,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_primary_term\": {\n",
      "   \"total\": \"0b\",\n",
      "   \"total_in_bytes\": 0,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_seq_no\": {\n",
      "   \"total\": \"87.9mb\",\n",
      "   \"total_in_bytes\": 92210789,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"57.5mb\",\n",
      "   \"doc_values_in_bytes\": 60355356,\n",
      "   \"points\": \"30.3mb\",\n",
      "   \"points_in_bytes\": 31855433,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_source\": {\n",
      "   \"total\": \"2.2gb\",\n",
      "   \"total_in_bytes\": 2428932102,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"2.2gb\",\n",
      "   \"stored_fields_in_bytes\": 2428932102,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_version\": {\n",
      "   \"total\": \"0b\",\n",
      "   \"total_in_bytes\": 0,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"agencia\": {\n",
      "   \"total\": \"34.2mb\",\n",
      "   \"total_in_bytes\": 35951641,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"19.9mb\",\n",
      "    \"total_in_bytes\": 20949854\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"14.3mb\",\n",
      "   \"doc_values_in_bytes\": 15001787,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"descripcion\": {\n",
      "   \"total\": \"124.8mb\",\n",
      "   \"total_in_bytes\": 130870241,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"96.1mb\",\n",
      "    \"total_in_bytes\": 100870241\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"28.6mb\",\n",
      "   \"norms_in_bytes\": 30000000,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"fecha\": {\n",
      "   \"total\": \"296.2mb\",\n",
      "   \"total_in_bytes\": 310633305,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"114.4mb\",\n",
      "   \"doc_values_in_bytes\": 120000000,\n",
      "   \"points\": \"181.8mb\",\n",
      "   \"points_in_bytes\": 190633305,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"monto\": {\n",
      "   \"total\": \"224.9mb\",\n",
      "   \"total_in_bytes\": 235833997,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"100.1mb\",\n",
      "   \"doc_values_in_bytes\": 105000005,\n",
      "   \"points\": \"124.7mb\",\n",
      "   \"points_in_bytes\": 130833992,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"nota\": {\n",
      "   \"total\": \"325.4mb\",\n",
      "   \"total_in_bytes\": 341279789,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"296.8mb\",\n",
      "    \"total_in_bytes\": 311279789\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"28.6mb\",\n",
      "   \"norms_in_bytes\": 30000000,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"saldo\": {\n",
      "   \"total\": \"224.9mb\",\n",
      "   \"total_in_bytes\": 235897881,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"100.1mb\",\n",
      "   \"doc_values_in_bytes\": 105000005,\n",
      "   \"points\": \"124.8mb\",\n",
      "   \"points_in_bytes\": 130897876,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  }\n",
      " }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r = dumps(es.options(request_timeout=40).indices.disk_usage(index=\"extracto_cuenta_30m\", run_expensive_tasks=True)['extracto_cuenta_30m'], indent=1)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrayendo información importante de los datos recién obtenidos. El tamaño de almacenamiento de 30 documentos de 1 millón de registros con un peso en bruto de 5.26 gb (en escala binario), una vez cargado en la base de datos es **2.26 gb** (en escala binario). Esto nos da un radio de compresión de 0.4295 y una reducción de tamaño en memoria del 0.5704%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante al que se le debe prestar atención es el tamaño de los índices en memoria, reportando en el presente caso un tamaño total de todos los índices de **1.66 gb** (en escala base binario). Otro número presente en el reporte de uso de almacenamiento es el número de secuencia, encargado de contar el número de operaciones realizadas en el índice, con un tamaño de **0.085 gb** (en escala base binario). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumando el tamaño de almacenamiento de los documentos, el total de los índices y otros números relevantes, se alcanza un tamaño de almacenamiento en memoria total de **4.01 gb** (en escala base binario)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 30 millones de documentos](../imagenes-de-soporte/elastic-insert/storage_kibana_30M_documents.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la figura superior podemos ver que la herramienta gráfica Kibana índica un tamaño de almacenamiento total de **138.37 mb**, número ligeramente mayor al calculado anteriormente, ya que podrían estarse ignorando algunos metadatos pequeños."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido       |\n",
    "|---------------------------------------------|----------------------|\n",
    "| Tiempo de carga                             | 2 h 43 min y 20.68 s |\n",
    "| Tamaño JSON bruto                           | 5.26 gb              |\n",
    "| Tamaño de almacenamiento en elasticsearch   | 2.26 gb              |\n",
    "| Radio de compresión de documento            | 0.4295               |\n",
    "| Reducción de tamaño de memoria de documento | 57.04 %              |\n",
    "| Tamaño total de los índices                 | 1.66 gb              |\n",
    "| Tamaño de número de secuencia               | 0.085 gb             |\n",
    "| Tamaño total de almacenamiento colección    | 4.01 gb              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 10 millones de documentos (solo 3 campos: fecha, descripción, nota)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga y el tamaño de almacenamiento de 10 millones de documentos indexados solo sobre 3 campos: fecha, descripción y nota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-elastic-3-index.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-elastic-3-index.py -n 10\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El script antes mencionado recibe como entrada la cantidad de documentos que cargará a la base de datos. Secuencialmente, el código creará la nueva colección donde se cargarán los datos, se mapeará los campos y declarará cuales se indexarán (fecha, descripción, nota). Posteriormente, se cargará la información almacenada en un documento JSON de forma masiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../imagenes-de-soporte/elastic-insert/load_10M_documents_3_index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 10 millones de documentos ha tomado un tiempo de **47 minutos y 39.02 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en el índice ```extracto_cuenta_10m_3idx``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 10000000 documentos en el índice 'extracto_cuenta_10m_3idx'\n"
     ]
    }
   ],
   "source": [
    "cnt = es.cat.count(index=\"extracto_cuenta_10m_3idx\", format= \"json\")[0]['count']\n",
    "print(f\"Actualmente existen {cnt} documentos en el índice 'extracto_cuenta_10m_3idx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte del índice ```extracto_cuenta_10m_3idx``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"store_size\": \"1.2gb\",\n",
      " \"store_size_in_bytes\": 1343700157,\n",
      " \"all_fields\": {\n",
      "  \"total\": \"1.2gb\",\n",
      "  \"total_in_bytes\": 1343036611,\n",
      "  \"inverted_index\": {\n",
      "   \"total\": \"184.9mb\",\n",
      "   \"total_in_bytes\": 193949507\n",
      "  },\n",
      "  \"stored_fields\": \"876.7mb\",\n",
      "  \"stored_fields_in_bytes\": 919336222,\n",
      "  \"doc_values\": \"128.7mb\",\n",
      "  \"doc_values_in_bytes\": 135012715,\n",
      "  \"points\": \"71.2mb\",\n",
      "  \"points_in_bytes\": 74738167,\n",
      "  \"norms\": \"19mb\",\n",
      "  \"norms_in_bytes\": 20000000,\n",
      "  \"term_vectors\": \"0b\",\n",
      "  \"term_vectors_in_bytes\": 0,\n",
      "  \"knn_vectors\": \"0b\",\n",
      "  \"knn_vectors_in_bytes\": 0\n",
      " },\n",
      " \"fields\": {\n",
      "  \"_id\": {\n",
      "   \"total\": \"158.2mb\",\n",
      "   \"total_in_bytes\": 165982774,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"53.8mb\",\n",
      "    \"total_in_bytes\": 56453555\n",
      "   },\n",
      "   \"stored_fields\": \"104.4mb\",\n",
      "   \"stored_fields_in_bytes\": 109529219,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_primary_term\": {\n",
      "   \"total\": \"0b\",\n",
      "   \"total_in_bytes\": 0,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_seq_no\": {\n",
      "   \"total\": \"29.2mb\",\n",
      "   \"total_in_bytes\": 30623572,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"19mb\",\n",
      "   \"doc_values_in_bytes\": 20011581,\n",
      "   \"points\": \"10.1mb\",\n",
      "   \"points_in_bytes\": 10611991,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_source\": {\n",
      "   \"total\": \"772.2mb\",\n",
      "   \"total_in_bytes\": 809807003,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"772.2mb\",\n",
      "   \"stored_fields_in_bytes\": 809807003,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_version\": {\n",
      "   \"total\": \"0b\",\n",
      "   \"total_in_bytes\": 0,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"agencia\": {\n",
      "   \"total\": \"4.7mb\",\n",
      "   \"total_in_bytes\": 5001126,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"4.7mb\",\n",
      "   \"doc_values_in_bytes\": 5001126,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"descripcion\": {\n",
      "   \"total\": \"41.6mb\",\n",
      "   \"total_in_bytes\": 43659678,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"32.1mb\",\n",
      "    \"total_in_bytes\": 33659678\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"9.5mb\",\n",
      "   \"norms_in_bytes\": 10000000,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"fecha\": {\n",
      "   \"total\": \"99.3mb\",\n",
      "   \"total_in_bytes\": 104126176,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"38.1mb\",\n",
      "   \"doc_values_in_bytes\": 40000000,\n",
      "   \"points\": \"61.1mb\",\n",
      "   \"points_in_bytes\": 64126176,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"monto\": {\n",
      "   \"total\": \"33.3mb\",\n",
      "   \"total_in_bytes\": 35000004,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"33.3mb\",\n",
      "   \"doc_values_in_bytes\": 35000004,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"nota\": {\n",
      "   \"total\": \"108.5mb\",\n",
      "   \"total_in_bytes\": 113836274,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"99mb\",\n",
      "    \"total_in_bytes\": 103836274\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"9.5mb\",\n",
      "   \"norms_in_bytes\": 10000000,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"saldo\": {\n",
      "   \"total\": \"33.3mb\",\n",
      "   \"total_in_bytes\": 35000004,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"33.3mb\",\n",
      "   \"doc_values_in_bytes\": 35000004,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  }\n",
      " }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r = dumps(es.options(request_timeout=30).indices.disk_usage(index=\"extracto_cuenta_10m_3idx\", run_expensive_tasks=True)['extracto_cuenta_10m_3idx'], indent=1)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por la información recopilada anteriormente, se sabe que el tamaño en almacenamiento aproximado de 10 documentos de 1 millón de registros con un peso en bruto de 1.75 gb (en escala base binario), una vez cargado en la base de datos es **0.75 gb** (en escala base binario). Esto nos da un radio de compresión de 0.4297 y una reducción de tamaño en memoria del 57.03%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante al que se le debe prestar atención es el tamaño de los índices en memoria, reportando en el presente caso un tamaño total de todos los índices de **0.47 gb** (en escala base binario). Otro número presente en el reporte de uso de almacenamiento es el número de secuencia, encargado de contar el número de operaciones realizadas en el índice, con un tamaño de **0.028 gb** (en escala base binario). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumando el tamaño de almacenamiento de los documentos, el total de los índices y otros números relevantes, se alcanza un tamaño de almacenamiento en memoria total de **1.25 gb** (en escala base binario)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cargando 10 millones de documentos](../imagenes-de-soporte/elastic-insert/storage_kibana_10M_documents_3idx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido |\n",
    "|---------------------------------------------|----------------|\n",
    "| Tiempo de carga                             | 47 min 39.02 s |\n",
    "| Tamaño JSON bruto                           | 1.75 gb        |\n",
    "| Tamaño de almacenamiento en elasticsearch   | 0.75 gb        |\n",
    "| Radio de compresión de documento            | 0.4297         |\n",
    "| Reducción de tamaño de memoria de documento | 57.03 %        |\n",
    "| Tamaño total de los índices                 | 0.47 gb        |\n",
    "| Tamaño de número de secuencia               | 0.028 gb       |\n",
    "| Tamaño total de almacenamiento colección    | 1.25 gb        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de 30 millones de documentos (solo 3 campos: fecha, descripción, nota)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se revisará la carga y el tamaño de almacenamiento de 30 millones de documentos indexados solo sobre 3 campos: fecha, descripción y nota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carga de documentos se llevará a cabo mediante el script de python ```load-documents-elastic-3-index.py``` localizado en el mismo directorio de este cuaderno. Para cargar la cantidad de datos en cuestión se ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python load-documents-elastic-3-index.py -n 30\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** es recomendable ejecutar el comando en una terminal aparte de este cuaderno, ya que se trata de una operación que dependiendo la cantidad de documentos, puede llegar a ocupar una considerable cantidad de memoria del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../imagenes-de-soporte/elastic-insert/load_30M_documentos_elastic_3_index.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la imagen superior, cargar 10 millones de documentos ha tomado un tiempo de **2 horas 17 minutos y 2.55 segundos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los documentos en la base de datos, podemos verificar la cantidad total de documentos en el índice ```extracto_cuenta_30m_3idx``` de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualmente existen 30000000 documentos en el índice 'extracto_cuenta_30m_3idx'\n"
     ]
    }
   ],
   "source": [
    "cnt = es.cat.count(index=\"extracto_cuenta_30m_3idx\", format= \"json\")[0]['count']\n",
    "print(f\"Actualmente existen {cnt} documentos en el índice 'extracto_cuenta_30m_3idx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tamaño de almacenamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las estadísticas de uso de disco por parte del índice ```extracto_cuenta_30m``` en la base de datos ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"store_size\": \"3.7gb\",\n",
      " \"store_size_in_bytes\": 4045396917,\n",
      " \"all_fields\": {\n",
      "  \"total\": \"3.7gb\",\n",
      "  \"total_in_bytes\": 4043737642,\n",
      "  \"inverted_index\": {\n",
      "   \"total\": \"555.3mb\",\n",
      "   \"total_in_bytes\": 582330007\n",
      "  },\n",
      "  \"stored_fields\": \"2.5gb\",\n",
      "  \"stored_fields_in_bytes\": 2757844242,\n",
      "  \"doc_values\": \"386.5mb\",\n",
      "  \"doc_values_in_bytes\": 405330672,\n",
      "  \"points\": \"227.1mb\",\n",
      "  \"points_in_bytes\": 238232721,\n",
      "  \"norms\": \"57.2mb\",\n",
      "  \"norms_in_bytes\": 60000000,\n",
      "  \"term_vectors\": \"0b\",\n",
      "  \"term_vectors_in_bytes\": 0,\n",
      "  \"knn_vectors\": \"0b\",\n",
      "  \"knn_vectors_in_bytes\": 0\n",
      " },\n",
      " \"fields\": {\n",
      "  \"_id\": {\n",
      "   \"total\": \"475.1mb\",\n",
      "   \"total_in_bytes\": 498219743,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"162.1mb\",\n",
      "    \"total_in_bytes\": 170057039\n",
      "   },\n",
      "   \"stored_fields\": \"312.9mb\",\n",
      "   \"stored_fields_in_bytes\": 328162704,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_primary_term\": {\n",
      "   \"total\": \"0b\",\n",
      "   \"total_in_bytes\": 0,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_seq_no\": {\n",
      "   \"total\": \"87.9mb\",\n",
      "   \"total_in_bytes\": 92224007,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"57.5mb\",\n",
      "   \"doc_values_in_bytes\": 60328935,\n",
      "   \"points\": \"30.4mb\",\n",
      "   \"points_in_bytes\": 31895072,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_source\": {\n",
      "   \"total\": \"2.2gb\",\n",
      "   \"total_in_bytes\": 2429681538,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"2.2gb\",\n",
      "   \"stored_fields_in_bytes\": 2429681538,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"_version\": {\n",
      "   \"total\": \"0b\",\n",
      "   \"total_in_bytes\": 0,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"agencia\": {\n",
      "   \"total\": \"14.3mb\",\n",
      "   \"total_in_bytes\": 15001723,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"14.3mb\",\n",
      "   \"doc_values_in_bytes\": 15001723,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"descripcion\": {\n",
      "   \"total\": \"124.8mb\",\n",
      "   \"total_in_bytes\": 130903530,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"96.2mb\",\n",
      "    \"total_in_bytes\": 100903530\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"28.6mb\",\n",
      "   \"norms_in_bytes\": 30000000,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"fecha\": {\n",
      "   \"total\": \"311.2mb\",\n",
      "   \"total_in_bytes\": 326337649,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"114.4mb\",\n",
      "   \"doc_values_in_bytes\": 120000000,\n",
      "   \"points\": \"196.7mb\",\n",
      "   \"points_in_bytes\": 206337649,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"monto\": {\n",
      "   \"total\": \"100.1mb\",\n",
      "   \"total_in_bytes\": 105000007,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"100.1mb\",\n",
      "   \"doc_values_in_bytes\": 105000007,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"nota\": {\n",
      "   \"total\": \"325.5mb\",\n",
      "   \"total_in_bytes\": 341369438,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"296.9mb\",\n",
      "    \"total_in_bytes\": 311369438\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"0b\",\n",
      "   \"doc_values_in_bytes\": 0,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"28.6mb\",\n",
      "   \"norms_in_bytes\": 30000000,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  },\n",
      "  \"saldo\": {\n",
      "   \"total\": \"100.1mb\",\n",
      "   \"total_in_bytes\": 105000007,\n",
      "   \"inverted_index\": {\n",
      "    \"total\": \"0b\",\n",
      "    \"total_in_bytes\": 0\n",
      "   },\n",
      "   \"stored_fields\": \"0b\",\n",
      "   \"stored_fields_in_bytes\": 0,\n",
      "   \"doc_values\": \"100.1mb\",\n",
      "   \"doc_values_in_bytes\": 105000007,\n",
      "   \"points\": \"0b\",\n",
      "   \"points_in_bytes\": 0,\n",
      "   \"norms\": \"0b\",\n",
      "   \"norms_in_bytes\": 0,\n",
      "   \"term_vectors\": \"0b\",\n",
      "   \"term_vectors_in_bytes\": 0,\n",
      "   \"knn_vectors\": \"0b\",\n",
      "   \"knn_vectors_in_bytes\": 0\n",
      "  }\n",
      " }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r = dumps(es.options(request_timeout=30).indices.disk_usage(index=\"extracto_cuenta_30m_3idx\", run_expensive_tasks=True)['extracto_cuenta_30m_3idx'], indent=1)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrayendo información importante de los datos recién obtenidos. El tamaño de almacenamiento de 30 documentos de 1 millón de registros con un peso en bruto de 5.26 gb (en escala binario), una vez cargado en la base de datos es **2.26 gb** (en escala binario). Esto nos da un radio de compresión de 0.4297 y una reducción de tamaño en memoria del 57.03%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro número importante al que se le debe prestar atención es el tamaño de los índices en memoria, reportando en el presente caso un tamaño total de todos los índices de **1.42 gb** (en escala base binario). Otro número presente en el reporte de uso de almacenamiento es el número de secuencia, encargado de contar el número de operaciones realizadas en el índice, con un tamaño de **0.086 gb** (en escala base binario). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumando el tamaño de almacenamiento de los documentos, el total de los índices y otros números relevantes, se alcanza un tamaño de almacenamiento en memoria total de **3.77 gb** (en escala base binario)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../imagenes-de-soporte/elastic-insert/storage_kibana_30M_documents_3_idx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Tabla resumen de resultados                 | Valor obtenido       |\n",
    "|---------------------------------------------|----------------------|\n",
    "| Tiempo de carga                             | 2 h 17 min  2.55 s   |\n",
    "| Tamaño JSON bruto                           | 5.26 gb              |\n",
    "| Tamaño de almacenamiento en elasticsearch   | 2.26 gb              |\n",
    "| Radio de compresión de documento            | 0.4297               |\n",
    "| Reducción de tamaño de memoria de documento | 57.03 %              |\n",
    "| Tamaño total de los índices                 | 1.42 gb              |\n",
    "| Tamaño de número de secuencia               | 0.086 gb             |\n",
    "| Tamaño total de almacenamiento colección    | 3.77 gb              |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7e5a1f785ed82844e2da5d30522181462e1597dbd1807cbc4c5c0cc1d5a2e0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
